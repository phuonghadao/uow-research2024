{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nganguyen1234/uow-research2024/blob/main/TrojanModel10_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kh6YWhpd7AHW"
      },
      "source": [
        "# **Runtime: T4 - GPU**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTlW11XUxsXm"
      },
      "source": [
        "# Tensorflow 1.15\n",
        "\n",
        "Instruction Reference\n",
        "https://github.com/googlecolab/colabtools/issues/3266"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXrvP0eJxr2n",
        "outputId": "16d1bcf3-2b34-4dad-d66f-5c9567082951"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PYTHONPATH=# /env/python\n"
          ]
        }
      ],
      "source": [
        "%env PYTHONPATH = # /env/python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrjDJUaexybY",
        "outputId": "c001dbe9-a257-4b34-9600-f18cd131e39c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-09-25 06:42:30--  https://repo.anaconda.com/miniconda/Miniconda3-py38_4.12.0-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.191.158, 104.16.32.241, 2606:4700::6810:20f1, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.191.158|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 76120962 (73M) [application/x-sh]\n",
            "Saving to: ‘Miniconda3-py38_4.12.0-Linux-x86_64.sh’\n",
            "\n",
            "Miniconda3-py38_4.1 100%[===================>]  72.59M   143MB/s    in 0.5s    \n",
            "\n",
            "2024-09-25 06:42:30 (143 MB/s) - ‘Miniconda3-py38_4.12.0-Linux-x86_64.sh’ saved [76120962/76120962]\n",
            "\n",
            "PREFIX=/usr/local\n",
            "Unpacking payload ...\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\b\\ \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - _libgcc_mutex==0.1=main\n",
            "    - _openmp_mutex==4.5=1_gnu\n",
            "    - brotlipy==0.7.0=py38h27cfd23_1003\n",
            "    - ca-certificates==2022.3.29=h06a4308_1\n",
            "    - certifi==2021.10.8=py38h06a4308_2\n",
            "    - cffi==1.15.0=py38hd667e15_1\n",
            "    - charset-normalizer==2.0.4=pyhd3eb1b0_0\n",
            "    - colorama==0.4.4=pyhd3eb1b0_0\n",
            "    - conda-content-trust==0.1.1=pyhd3eb1b0_0\n",
            "    - conda-package-handling==1.8.1=py38h7f8727e_0\n",
            "    - conda==4.12.0=py38h06a4308_0\n",
            "    - cryptography==36.0.0=py38h9ce1e76_0\n",
            "    - idna==3.3=pyhd3eb1b0_0\n",
            "    - ld_impl_linux-64==2.35.1=h7274673_9\n",
            "    - libffi==3.3=he6710b0_2\n",
            "    - libgcc-ng==9.3.0=h5101ec6_17\n",
            "    - libgomp==9.3.0=h5101ec6_17\n",
            "    - libstdcxx-ng==9.3.0=hd4cf53a_17\n",
            "    - ncurses==6.3=h7f8727e_2\n",
            "    - openssl==1.1.1n=h7f8727e_0\n",
            "    - pip==21.2.4=py38h06a4308_0\n",
            "    - pycosat==0.6.3=py38h7b6447c_1\n",
            "    - pycparser==2.21=pyhd3eb1b0_0\n",
            "    - pyopenssl==22.0.0=pyhd3eb1b0_0\n",
            "    - pysocks==1.7.1=py38h06a4308_0\n",
            "    - python==3.8.13=h12debd9_0\n",
            "    - readline==8.1.2=h7f8727e_1\n",
            "    - requests==2.27.1=pyhd3eb1b0_0\n",
            "    - ruamel_yaml==0.15.100=py38h27cfd23_0\n",
            "    - setuptools==61.2.0=py38h06a4308_0\n",
            "    - six==1.16.0=pyhd3eb1b0_1\n",
            "    - sqlite==3.38.2=hc218d9a_0\n",
            "    - tk==8.6.11=h1ccaba5_0\n",
            "    - tqdm==4.63.0=pyhd3eb1b0_0\n",
            "    - urllib3==1.26.8=pyhd3eb1b0_0\n",
            "    - wheel==0.37.1=pyhd3eb1b0_0\n",
            "    - xz==5.2.5=h7b6447c_0\n",
            "    - yaml==0.2.5=h7b6447c_0\n",
            "    - zlib==1.2.12=h7f8727e_1\n",
            "\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main\n",
            "  _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-4.5-1_gnu\n",
            "  brotlipy           pkgs/main/linux-64::brotlipy-0.7.0-py38h27cfd23_1003\n",
            "  ca-certificates    pkgs/main/linux-64::ca-certificates-2022.3.29-h06a4308_1\n",
            "  certifi            pkgs/main/linux-64::certifi-2021.10.8-py38h06a4308_2\n",
            "  cffi               pkgs/main/linux-64::cffi-1.15.0-py38hd667e15_1\n",
            "  charset-normalizer pkgs/main/noarch::charset-normalizer-2.0.4-pyhd3eb1b0_0\n",
            "  colorama           pkgs/main/noarch::colorama-0.4.4-pyhd3eb1b0_0\n",
            "  conda              pkgs/main/linux-64::conda-4.12.0-py38h06a4308_0\n",
            "  conda-content-tru~ pkgs/main/noarch::conda-content-trust-0.1.1-pyhd3eb1b0_0\n",
            "  conda-package-han~ pkgs/main/linux-64::conda-package-handling-1.8.1-py38h7f8727e_0\n",
            "  cryptography       pkgs/main/linux-64::cryptography-36.0.0-py38h9ce1e76_0\n",
            "  idna               pkgs/main/noarch::idna-3.3-pyhd3eb1b0_0\n",
            "  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.35.1-h7274673_9\n",
            "  libffi             pkgs/main/linux-64::libffi-3.3-he6710b0_2\n",
            "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-9.3.0-h5101ec6_17\n",
            "  libgomp            pkgs/main/linux-64::libgomp-9.3.0-h5101ec6_17\n",
            "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-9.3.0-hd4cf53a_17\n",
            "  ncurses            pkgs/main/linux-64::ncurses-6.3-h7f8727e_2\n",
            "  openssl            pkgs/main/linux-64::openssl-1.1.1n-h7f8727e_0\n",
            "  pip                pkgs/main/linux-64::pip-21.2.4-py38h06a4308_0\n",
            "  pycosat            pkgs/main/linux-64::pycosat-0.6.3-py38h7b6447c_1\n",
            "  pycparser          pkgs/main/noarch::pycparser-2.21-pyhd3eb1b0_0\n",
            "  pyopenssl          pkgs/main/noarch::pyopenssl-22.0.0-pyhd3eb1b0_0\n",
            "  pysocks            pkgs/main/linux-64::pysocks-1.7.1-py38h06a4308_0\n",
            "  python             pkgs/main/linux-64::python-3.8.13-h12debd9_0\n",
            "  readline           pkgs/main/linux-64::readline-8.1.2-h7f8727e_1\n",
            "  requests           pkgs/main/noarch::requests-2.27.1-pyhd3eb1b0_0\n",
            "  ruamel_yaml        pkgs/main/linux-64::ruamel_yaml-0.15.100-py38h27cfd23_0\n",
            "  setuptools         pkgs/main/linux-64::setuptools-61.2.0-py38h06a4308_0\n",
            "  six                pkgs/main/noarch::six-1.16.0-pyhd3eb1b0_1\n",
            "  sqlite             pkgs/main/linux-64::sqlite-3.38.2-hc218d9a_0\n",
            "  tk                 pkgs/main/linux-64::tk-8.6.11-h1ccaba5_0\n",
            "  tqdm               pkgs/main/noarch::tqdm-4.63.0-pyhd3eb1b0_0\n",
            "  urllib3            pkgs/main/noarch::urllib3-1.26.8-pyhd3eb1b0_0\n",
            "  wheel              pkgs/main/noarch::wheel-0.37.1-pyhd3eb1b0_0\n",
            "  xz                 pkgs/main/linux-64::xz-5.2.5-h7b6447c_0\n",
            "  yaml               pkgs/main/linux-64::yaml-0.2.5-h7b6447c_0\n",
            "  zlib               pkgs/main/linux-64::zlib-1.2.12-h7f8727e_1\n",
            "\n",
            "\n",
            "Preparing transaction: / \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Executing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "  current version: 4.12.0\n",
            "  latest version: 24.7.1\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c defaults conda\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - conda\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    _openmp_mutex-5.1          |            1_gnu          21 KB\n",
            "    brotli-python-1.0.9        |   py38h6a678d5_8         356 KB\n",
            "    ca-certificates-2024.7.2   |       h06a4308_0         127 KB\n",
            "    certifi-2024.8.30          |   py38h06a4308_0         162 KB\n",
            "    cffi-1.17.1                |   py38h1fdaa30_0         253 KB\n",
            "    charset-normalizer-3.3.2   |     pyhd3eb1b0_0          44 KB\n",
            "    conda-package-handling-2.3.0|   py38h06a4308_0         269 KB\n",
            "    conda-package-streaming-0.10.0|   py38h06a4308_0          27 KB\n",
            "    cryptography-43.0.0        |   py38hdda0065_0         2.2 MB\n",
            "    idna-3.7                   |   py38h06a4308_0         113 KB\n",
            "    ld_impl_linux-64-2.38      |       h1181459_1         654 KB\n",
            "    libffi-3.4.4               |       h6a678d5_1         141 KB\n",
            "    libgcc-ng-11.2.0           |       h1234567_1         5.3 MB\n",
            "    libgomp-11.2.0             |       h1234567_1         474 KB\n",
            "    libstdcxx-ng-11.2.0        |       h1234567_1         4.7 MB\n",
            "    lz4-c-1.9.4                |       h6a678d5_1         156 KB\n",
            "    ncurses-6.4                |       h6a678d5_0         914 KB\n",
            "    openssl-3.0.15             |       h5eee18b_0         5.2 MB\n",
            "    pip-24.2                   |   py38h06a4308_0         2.2 MB\n",
            "    pycosat-0.6.6              |   py38h5eee18b_1          93 KB\n",
            "    pyopenssl-24.2.1           |   py38h06a4308_0          96 KB\n",
            "    python-3.8.19              |       h955ad1f_0        23.8 MB\n",
            "    readline-8.2               |       h5eee18b_0         357 KB\n",
            "    requests-2.32.3            |   py38h06a4308_0         100 KB\n",
            "    setuptools-75.1.0          |   py38h06a4308_0         1.7 MB\n",
            "    sqlite-3.45.3              |       h5eee18b_0         1.2 MB\n",
            "    tk-8.6.14                  |       h39e8969_0         3.4 MB\n",
            "    urllib3-2.2.2              |   py38h06a4308_0         177 KB\n",
            "    wheel-0.44.0               |   py38h06a4308_0         108 KB\n",
            "    xz-5.4.6                   |       h5eee18b_1         643 KB\n",
            "    zlib-1.2.13                |       h5eee18b_1         111 KB\n",
            "    zstandard-0.22.0           |   py38h2c38b39_0         427 KB\n",
            "    zstd-1.5.5                 |       hc292b87_2         643 KB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        56.1 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  brotli-python      pkgs/main/linux-64::brotli-python-1.0.9-py38h6a678d5_8\n",
            "  conda-package-str~ pkgs/main/linux-64::conda-package-streaming-0.10.0-py38h06a4308_0\n",
            "  lz4-c              pkgs/main/linux-64::lz4-c-1.9.4-h6a678d5_1\n",
            "  zstandard          pkgs/main/linux-64::zstandard-0.22.0-py38h2c38b39_0\n",
            "  zstd               pkgs/main/linux-64::zstd-1.5.5-hc292b87_2\n",
            "\n",
            "The following packages will be REMOVED:\n",
            "\n",
            "  brotlipy-0.7.0-py38h27cfd23_1003\n",
            "  colorama-0.4.4-pyhd3eb1b0_0\n",
            "  conda-content-trust-0.1.1-pyhd3eb1b0_0\n",
            "  six-1.16.0-pyhd3eb1b0_1\n",
            "  tqdm-4.63.0-pyhd3eb1b0_0\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  _openmp_mutex                                   4.5-1_gnu --> 5.1-1_gnu\n",
            "  ca-certificates                      2022.3.29-h06a4308_1 --> 2024.7.2-h06a4308_0\n",
            "  certifi                          2021.10.8-py38h06a4308_2 --> 2024.8.30-py38h06a4308_0\n",
            "  cffi                                1.15.0-py38hd667e15_1 --> 1.17.1-py38h1fdaa30_0\n",
            "  charset-normalizer                     2.0.4-pyhd3eb1b0_0 --> 3.3.2-pyhd3eb1b0_0\n",
            "  conda-package-han~                   1.8.1-py38h7f8727e_0 --> 2.3.0-py38h06a4308_0\n",
            "  cryptography                        36.0.0-py38h9ce1e76_0 --> 43.0.0-py38hdda0065_0\n",
            "  idna               pkgs/main/noarch::idna-3.3-pyhd3eb1b0~ --> pkgs/main/linux-64::idna-3.7-py38h06a4308_0\n",
            "  ld_impl_linux-64                        2.35.1-h7274673_9 --> 2.38-h1181459_1\n",
            "  libffi                                     3.3-he6710b0_2 --> 3.4.4-h6a678d5_1\n",
            "  libgcc-ng                               9.3.0-h5101ec6_17 --> 11.2.0-h1234567_1\n",
            "  libgomp                                 9.3.0-h5101ec6_17 --> 11.2.0-h1234567_1\n",
            "  libstdcxx-ng                            9.3.0-hd4cf53a_17 --> 11.2.0-h1234567_1\n",
            "  ncurses                                    6.3-h7f8727e_2 --> 6.4-h6a678d5_0\n",
            "  openssl                                 1.1.1n-h7f8727e_0 --> 3.0.15-h5eee18b_0\n",
            "  pip                                 21.2.4-py38h06a4308_0 --> 24.2-py38h06a4308_0\n",
            "  pycosat                              0.6.3-py38h7b6447c_1 --> 0.6.6-py38h5eee18b_1\n",
            "  pyopenssl          pkgs/main/noarch::pyopenssl-22.0.0-py~ --> pkgs/main/linux-64::pyopenssl-24.2.1-py38h06a4308_0\n",
            "  python                                  3.8.13-h12debd9_0 --> 3.8.19-h955ad1f_0\n",
            "  readline                                 8.1.2-h7f8727e_1 --> 8.2-h5eee18b_0\n",
            "  requests           pkgs/main/noarch::requests-2.27.1-pyh~ --> pkgs/main/linux-64::requests-2.32.3-py38h06a4308_0\n",
            "  setuptools                          61.2.0-py38h06a4308_0 --> 75.1.0-py38h06a4308_0\n",
            "  sqlite                                  3.38.2-hc218d9a_0 --> 3.45.3-h5eee18b_0\n",
            "  tk                                      8.6.11-h1ccaba5_0 --> 8.6.14-h39e8969_0\n",
            "  urllib3            pkgs/main/noarch::urllib3-1.26.8-pyhd~ --> pkgs/main/linux-64::urllib3-2.2.2-py38h06a4308_0\n",
            "  wheel              pkgs/main/noarch::wheel-0.37.1-pyhd3e~ --> pkgs/main/linux-64::wheel-0.44.0-py38h06a4308_0\n",
            "  xz                                       5.2.5-h7b6447c_0 --> 5.4.6-h5eee18b_1\n",
            "  zlib                                    1.2.12-h7f8727e_1 --> 1.2.13-h5eee18b_1\n",
            "\n",
            "\n",
            "Proceed ([y]/n)? y\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "cryptography-43.0.0  | 2.2 MB    | : 100% 1.0/1 [00:00<00:00,  2.44it/s]\n",
            "readline-8.2         | 357 KB    | : 100% 1.0/1 [00:00<00:00,  5.49it/s]\n",
            "_openmp_mutex-5.1    | 21 KB     | : 100% 1.0/1 [00:00<00:00,  5.41it/s]\n",
            "tk-8.6.14            | 3.4 MB    | : 100% 1.0/1 [00:00<00:00,  2.97it/s]\n",
            "pyopenssl-24.2.1     | 96 KB     | : 100% 1.0/1 [00:00<00:00,  6.45it/s]\n",
            "xz-5.4.6             | 643 KB    | : 100% 1.0/1 [00:00<00:00,  4.95it/s]\n",
            "pip-24.2             | 2.2 MB    | : 100% 1.0/1 [00:00<00:00,  3.16it/s]\n",
            "requests-2.32.3      | 100 KB    | : 100% 1.0/1 [00:00<00:00,  6.43it/s]\n",
            "libffi-3.4.4         | 141 KB    | : 100% 1.0/1 [00:00<00:00,  5.52it/s]\n",
            "ncurses-6.4          | 914 KB    | : 100% 1.0/1 [00:00<00:00,  2.47it/s]\n",
            "zlib-1.2.13          | 111 KB    | : 100% 1.0/1 [00:00<00:00,  6.68it/s]\n",
            "ld_impl_linux-64-2.3 | 654 KB    | : 100% 1.0/1 [00:00<00:00,  5.88it/s]\n",
            "python-3.8.19        | 23.8 MB   | : 100% 1.0/1 [00:01<00:00,  1.37s/it]               \n",
            "conda-package-handli | 269 KB    | : 100% 1.0/1 [00:00<00:00,  6.18it/s]\n",
            "cffi-1.17.1          | 253 KB    | : 100% 1.0/1 [00:00<00:00,  6.10it/s]\n",
            "setuptools-75.1.0    | 1.7 MB    | : 100% 1.0/1 [00:00<00:00,  3.22it/s]\n",
            "libstdcxx-ng-11.2.0  | 4.7 MB    | : 100% 1.0/1 [00:00<00:00,  3.48it/s]\n",
            "conda-package-stream | 27 KB     | : 100% 1.0/1 [00:00<00:00,  6.69it/s]\n",
            "libgomp-11.2.0       | 474 KB    | : 100% 1.0/1 [00:00<00:00,  5.13it/s]\n",
            "urllib3-2.2.2        | 177 KB    | : 100% 1.0/1 [00:00<00:00,  2.81it/s]\n",
            "zstandard-0.22.0     | 427 KB    | : 100% 1.0/1 [00:00<00:00,  4.33it/s]\n",
            "idna-3.7             | 113 KB    | : 100% 1.0/1 [00:00<00:00,  6.02it/s]\n",
            "libgcc-ng-11.2.0     | 5.3 MB    | : 100% 1.0/1 [00:00<00:00,  3.32it/s]\n",
            "wheel-0.44.0         | 108 KB    | : 100% 1.0/1 [00:00<00:00,  3.19it/s]\n",
            "certifi-2024.8.30    | 162 KB    | : 100% 1.0/1 [00:00<00:00,  4.40it/s]\n",
            "charset-normalizer-3 | 44 KB     | : 100% 1.0/1 [00:00<00:00,  6.33it/s]\n",
            "lz4-c-1.9.4          | 156 KB    | : 100% 1.0/1 [00:00<00:00,  6.55it/s]\n",
            "sqlite-3.45.3        | 1.2 MB    | : 100% 1.0/1 [00:00<00:00,  5.43it/s]\n",
            "ca-certificates-2024 | 127 KB    | : 100% 1.0/1 [00:00<00:00,  4.86it/s]\n",
            "openssl-3.0.15       | 5.2 MB    | : 100% 1.0/1 [00:00<00:00,  1.60it/s]              \n",
            "pycosat-0.6.6        | 93 KB     | : 100% 1.0/1 [00:00<00:00,  6.59it/s]\n",
            "zstd-1.5.5           | 643 KB    | : 100% 1.0/1 [00:00<00:00,  5.66it/s]\n",
            "brotli-python-1.0.9  | 356 KB    | : 100% 1.0/1 [00:00<00:00,  6.18it/s]\n",
            "Preparing transaction: | \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Verifying transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Executing transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n"
          ]
        }
      ],
      "source": [
        "!wget https://repo.anaconda.com/miniconda/Miniconda3-py38_4.12.0-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-py38_4.12.0-Linux-x86_64.sh\n",
        "!./Miniconda3-py38_4.12.0-Linux-x86_64.sh -b -f -p /usr/local\n",
        "!conda update conda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9HITWNJrx0qv"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.8/site-packages')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlsr_ttfx1hQ",
        "outputId": "6cb2db05-9764-46d0-ccbd-9449a57aaae8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Solving environment: / \b\bfailed with repodata from current_repodata.json, will retry with next repodata source.\n",
            "Collecting package metadata (repodata.json): \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "  current version: 4.12.0\n",
            "  latest version: 24.7.1\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c defaults conda\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local/envs/myenv\n",
            "\n",
            "  added / updated specs:\n",
            "    - python=3.6\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    certifi-2021.5.30          |   py36h06a4308_0         139 KB\n",
            "    openssl-1.1.1w             |       h7f8727e_0         3.7 MB\n",
            "    pip-21.2.2                 |   py36h06a4308_0         1.8 MB\n",
            "    python-3.6.13              |       h12debd9_1        32.5 MB\n",
            "    setuptools-58.0.4          |   py36h06a4308_0         788 KB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        39.0 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main\n",
            "  _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-5.1-1_gnu\n",
            "  ca-certificates    pkgs/main/linux-64::ca-certificates-2024.7.2-h06a4308_0\n",
            "  certifi            pkgs/main/linux-64::certifi-2021.5.30-py36h06a4308_0\n",
            "  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.38-h1181459_1\n",
            "  libffi             pkgs/main/linux-64::libffi-3.3-he6710b0_2\n",
            "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-11.2.0-h1234567_1\n",
            "  libgomp            pkgs/main/linux-64::libgomp-11.2.0-h1234567_1\n",
            "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-11.2.0-h1234567_1\n",
            "  ncurses            pkgs/main/linux-64::ncurses-6.4-h6a678d5_0\n",
            "  openssl            pkgs/main/linux-64::openssl-1.1.1w-h7f8727e_0\n",
            "  pip                pkgs/main/linux-64::pip-21.2.2-py36h06a4308_0\n",
            "  python             pkgs/main/linux-64::python-3.6.13-h12debd9_1\n",
            "  readline           pkgs/main/linux-64::readline-8.2-h5eee18b_0\n",
            "  setuptools         pkgs/main/linux-64::setuptools-58.0.4-py36h06a4308_0\n",
            "  sqlite             pkgs/main/linux-64::sqlite-3.45.3-h5eee18b_0\n",
            "  tk                 pkgs/main/linux-64::tk-8.6.14-h39e8969_0\n",
            "  wheel              pkgs/main/noarch::wheel-0.37.1-pyhd3eb1b0_0\n",
            "  xz                 pkgs/main/linux-64::xz-5.4.6-h5eee18b_1\n",
            "  zlib               pkgs/main/linux-64::zlib-1.2.13-h5eee18b_1\n",
            "\n",
            "\n",
            "Proceed ([y]/n)? y\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "openssl-1.1.1w       | 3.7 MB    | : 100% 1.0/1 [00:00<00:00,  4.12it/s]\n",
            "python-3.6.13        | 32.5 MB   | : 100% 1.0/1 [00:08<00:00,  8.20s/it]               \n",
            "pip-21.2.2           | 1.8 MB    | : 100% 1.0/1 [00:00<00:00,  2.73it/s]\n",
            "certifi-2021.5.30    | 139 KB    | : 100% 1.0/1 [00:00<00:00, 25.41it/s]\n",
            "setuptools-58.0.4    | 788 KB    | : 100% 1.0/1 [00:00<00:00,  5.81it/s]\n",
            "Preparing transaction: - \b\b\\ \b\b| \b\bdone\n",
            "Verifying transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Executing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate myenv\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!conda create -n myenv python=3.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUr_fCLnx3fH",
        "outputId": "fc7af525-bcb5-4666-d557-cc76647d0512"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==1.15\n",
            "  Downloading tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (412.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3 MB 31 kB/s \n",
            "\u001b[?25hCollecting termcolor>=1.1.0\n",
            "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
            "Collecting wrapt>=1.11.1\n",
            "  Downloading wrapt-1.16.0-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 5.4 MB/s \n",
            "\u001b[?25hCollecting google-pasta>=0.1.6\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 6.2 MB/s \n",
            "\u001b[?25hCollecting protobuf>=3.6.1\n",
            "  Downloading protobuf-3.19.6-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 39.3 MB/s \n",
            "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
            "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 4.1 MB/s \n",
            "\u001b[?25hCollecting grpcio>=1.8.6\n",
            "  Downloading grpcio-1.48.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.6 MB 45.1 MB/s \n",
            "\u001b[?25hCollecting keras-preprocessing>=1.0.5\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.4 MB/s \n",
            "\u001b[?25hCollecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 45.2 MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 53.3 MB/s \n",
            "\u001b[?25hCollecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Collecting six>=1.10.0\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting numpy<2.0,>=1.16.0\n",
            "  Downloading numpy-1.19.5-cp36-cp36m-manylinux2010_x86_64.whl (14.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.8 MB 44.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorflow==1.15) (0.37.1)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 8.4 MB/s \n",
            "\u001b[?25hCollecting astor>=0.6.0\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Collecting absl-py>=0.7.0\n",
            "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
            "\u001b[K     |████████████████████████████████| 126 kB 54.4 MB/s \n",
            "\u001b[?25hCollecting h5py\n",
            "  Downloading h5py-3.1.0-cp36-cp36m-manylinux1_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 32.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (58.0.4)\n",
            "Collecting werkzeug>=0.11.15\n",
            "  Downloading Werkzeug-2.0.3-py3-none-any.whl (289 kB)\n",
            "\u001b[K     |████████████████████████████████| 289 kB 46.0 MB/s \n",
            "\u001b[?25hCollecting markdown>=2.6.8\n",
            "  Downloading Markdown-3.3.7-py3-none-any.whl (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 9.0 MB/s \n",
            "\u001b[?25hCollecting importlib-metadata>=4.4\n",
            "  Downloading importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\n",
            "Collecting typing-extensions>=3.6.4\n",
            "  Downloading typing_extensions-4.1.1-py3-none-any.whl (26 kB)\n",
            "Collecting zipp>=0.5\n",
            "  Downloading zipp-3.6.0-py3-none-any.whl (5.3 kB)\n",
            "Collecting dataclasses\n",
            "  Downloading dataclasses-0.8-py3-none-any.whl (19 kB)\n",
            "Collecting cached-property\n",
            "  Downloading cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Building wheels for collected packages: gast, termcolor\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=e25004e4e8f6b5ad3129a07d4aa572c3a589f7836cb4c248d890db57efdfb10c\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/a7/b9/0740c7a3a7d1d348f04823339274b90de25fbcd217b2ee1fbe\n",
            "  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4848 sha256=6412c9048690185ea99acdf8ca881bbaf4d602187514c377bcba788fe2a9d93d\n",
            "  Stored in directory: /root/.cache/pip/wheels/93/2a/eb/e58dbcbc963549ee4f065ff80a59f274cc7210b6eab962acdc\n",
            "Successfully built gast termcolor\n",
            "Installing collected packages: zipp, typing-extensions, six, numpy, importlib-metadata, dataclasses, cached-property, werkzeug, protobuf, markdown, h5py, grpcio, absl-py, wrapt, termcolor, tensorflow-estimator, tensorboard, opt-einsum, keras-preprocessing, keras-applications, google-pasta, gast, astor, tensorflow\n",
            "Successfully installed absl-py-1.4.0 astor-0.8.1 cached-property-1.5.2 dataclasses-0.8 gast-0.2.2 google-pasta-0.2.0 grpcio-1.48.2 h5py-3.1.0 importlib-metadata-4.8.3 keras-applications-1.0.8 keras-preprocessing-1.1.2 markdown-3.3.7 numpy-1.19.5 opt-einsum-3.3.0 protobuf-3.19.6 six-1.16.0 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1 termcolor-1.1.0 typing-extensions-4.1.1 werkzeug-2.0.3 wrapt-1.16.0 zipp-3.6.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "%%shell\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate myenv\n",
        "pip install tensorflow==1.15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fz4j9JW2x5vH",
        "outputId": "e4a25eda-7279-469d-b94b-174bfcecd56b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.15.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# check the version of the tensorflow\n",
        "%%shell\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate myenv\n",
        "python3 -c \"import tensorflow as tf; print(tf.__version__)\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%shell\n",
        "# Initialize the conda environment\n",
        "# eval \"$(conda shell.bash hook)\"\n",
        "\n",
        "# Activate your environment\n",
        "# conda activate myenv\n",
        "\n",
        "# Downgrade protobuf to a compatible version for TensorFlow 1.15\n",
        "# pip install protobuf==3.20.3\n",
        "\n",
        "# Verify the TensorFlow version\n",
        "# python3 -c \"import tensorflow as tf; print(tf.__version__)\"\n"
      ],
      "metadata": {
        "id": "jlXjPnsz8pcs"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1D4bh_Xx782"
      },
      "source": [
        "# CUDA 9.0\n",
        "\n",
        "Download CUDA toolkit from https://developer.nvidia.com/cuda-90-download-archive?target_os=Linux&target_arch=x86_64&target_distro=Ubuntu&target_version=1704&target_type=runfilelocal\n",
        "\n",
        "Operating System: Linux\n",
        "\n",
        "Architecture: x86_64\n",
        "\n",
        "Distribution: Ubuntu\n",
        "\n",
        "Version: 17.04\n",
        "\n",
        "Installer Type: runfile(local)\n",
        "\n",
        "Download: Base installer + Patch 4\n",
        "\n",
        "Upload noth downloaded files to Google Drive\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWlxUgmvLkF8",
        "outputId": "2ce7c863-c52f-4513-a569-1d382834f4d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\b\\ \b\b| \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "  current version: 4.12.0\n",
            "  latest version: 24.7.1\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c defaults conda\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local/envs/myenv\n",
            "\n",
            "  added / updated specs:\n",
            "    - cudatoolkit=9.0\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    cudatoolkit-9.0            |       h13b8566_0       237.0 MB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:       237.0 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  cudatoolkit        pkgs/main/linux-64::cudatoolkit-9.0-h13b8566_0\n",
            "\n",
            "\n",
            "Proceed ([y]/n)? y\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "cudatoolkit-9.0      | 237.0 MB  | : 100% 1.0/1 [00:07<00:00,  7.20s/it]               \n",
            "Preparing transaction: - \b\bdone\n",
            "Verifying transaction: | \b\b/ \b\bdone\n",
            "Executing transaction: \\ \b\bdone\n",
            "# packages in environment at /usr/local/envs/myenv:\n",
            "#\n",
            "# Name                    Version                   Build  Channel\n",
            "cudatoolkit               9.0                  h13b8566_0  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "%%shell\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate myenv\n",
        "\n",
        "# Your code here...\n",
        "\n",
        "\n",
        "\n",
        "conda install cudatoolkit=9.0\n",
        "\n",
        "# Check installed CUDA toolkit version via Conda\n",
        "conda list cudatoolkit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeniK3Rnf8qd"
      },
      "source": [
        "# **TESTING HERE NOT FINISH**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate myenv\n",
        "\n",
        "\n",
        "# Uninstall existing versions of TensorFlow and protobuf\n",
        "pip uninstall -y tensorflow tensorflow-gpu torch\n",
        "\n",
        "# Install specific versions of TensorFlow and protobuf\n",
        "pip install tensorflow==1.15.0 torch\n",
        "pip install python-levenshtein torch visdom wget librosa tqdm absl-py  pyroomacoustics matplotlib pandas pesq seaborn ipykernel\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4ow-zH99Xev",
        "outputId": "75433707-609a-474e-c3e6-b9473737d0a4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 1.15.0\n",
            "Uninstalling tensorflow-1.15.0:\n",
            "  Successfully uninstalled tensorflow-1.15.0\n",
            "\u001b[33mWARNING: Skipping tensorflow-gpu as it is not installed.\u001b[0m\n",
            "\u001b[33mWARNING: Skipping torch as it is not installed.\u001b[0m\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Collecting tensorflow==1.15.0\n",
            "  Using cached tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (412.3 MB)\n",
            "Collecting torch\n",
            "  Downloading torch-1.10.2-cp36-cp36m-manylinux1_x86_64.whl (881.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 881.9 MB 9.5 kB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorflow==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorflow==1.15.0) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorflow==1.15.0) (1.4.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorflow==1.15.0) (1.0.8)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorflow==1.15.0) (3.19.6)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorflow==1.15.0) (1.19.5)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorflow==1.15.0) (1.16.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorflow==1.15.0) (0.8.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorflow==1.15.0) (3.3.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorflow==1.15.0) (1.48.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorflow==1.15.0) (1.1.2)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorflow==1.15.0) (0.2.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorflow==1.15.0) (0.37.1)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorflow==1.15.0) (1.15.1)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorflow==1.15.0) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorflow==1.15.0) (1.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/envs/myenv/lib/python3.6/site-packages (from torch) (4.1.1)\n",
            "Requirement already satisfied: dataclasses in /usr/local/envs/myenv/lib/python3.6/site-packages (from torch) (0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/envs/myenv/lib/python3.6/site-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (3.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.3.7)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (2.0.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (58.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/envs/myenv/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (4.8.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/envs/myenv/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.6.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/envs/myenv/lib/python3.6/site-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15.0) (1.5.2)\n",
            "Installing collected packages: torch, tensorflow\n",
            "Successfully installed tensorflow-1.15.0 torch-1.10.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Collecting python-levenshtein\n",
            "  Downloading python_Levenshtein-0.21.1-py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: torch in /usr/local/envs/myenv/lib/python3.6/site-packages (1.10.2)\n",
            "Collecting visdom\n",
            "  Downloading visdom-0.2.4.tar.gz (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 5.2 MB/s \n",
            "\u001b[?25hCollecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Collecting librosa\n",
            "  Downloading librosa-0.9.2-py3-none-any.whl (214 kB)\n",
            "\u001b[K     |████████████████████████████████| 214 kB 45.0 MB/s \n",
            "\u001b[?25hCollecting tqdm\n",
            "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 8.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/envs/myenv/lib/python3.6/site-packages (1.4.0)\n",
            "Collecting pyroomacoustics\n",
            "  Downloading pyroomacoustics-0.7.7.tar.gz (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 41.2 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting matplotlib\n",
            "  Downloading matplotlib-3.3.4-cp36-cp36m-manylinux1_x86_64.whl (11.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.5 MB 29.4 MB/s \n",
            "\u001b[?25hCollecting pandas\n",
            "  Downloading pandas-1.1.5-cp36-cp36m-manylinux1_x86_64.whl (9.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.5 MB 57.2 MB/s \n",
            "\u001b[?25hCollecting pesq\n",
            "  Downloading pesq-0.0.4.tar.gz (38 kB)\n",
            "Collecting seaborn\n",
            "  Downloading seaborn-0.11.2-py3-none-any.whl (292 kB)\n",
            "\u001b[K     |████████████████████████████████| 292 kB 43.6 MB/s \n",
            "\u001b[?25hCollecting ipykernel\n",
            "  Downloading ipykernel-5.5.6-py3-none-any.whl (121 kB)\n",
            "\u001b[K     |████████████████████████████████| 121 kB 37.3 MB/s \n",
            "\u001b[?25hCollecting Levenshtein==0.21.1\n",
            "  Downloading Levenshtein-0.21.1-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (171 kB)\n",
            "\u001b[K     |████████████████████████████████| 171 kB 48.0 MB/s \n",
            "\u001b[?25hCollecting rapidfuzz<4.0.0,>=2.3.0\n",
            "  Downloading rapidfuzz-2.11.1-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 25.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/envs/myenv/lib/python3.6/site-packages (from torch) (4.1.1)\n",
            "Requirement already satisfied: dataclasses in /usr/local/envs/myenv/lib/python3.6/site-packages (from torch) (0.8)\n",
            "Requirement already satisfied: numpy>=1.8 in /usr/local/envs/myenv/lib/python3.6/site-packages (from visdom) (1.19.5)\n",
            "Collecting scipy\n",
            "  Downloading scipy-1.5.4-cp36-cp36m-manylinux1_x86_64.whl (25.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.9 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting requests\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.1 MB/s \n",
            "\u001b[?25hCollecting tornado\n",
            "  Downloading tornado-6.1-cp36-cp36m-manylinux2010_x86_64.whl (427 kB)\n",
            "\u001b[K     |████████████████████████████████| 427 kB 46.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/envs/myenv/lib/python3.6/site-packages (from visdom) (1.16.0)\n",
            "Collecting jsonpatch\n",
            "  Downloading jsonpatch-1.32-py2.py3-none-any.whl (12 kB)\n",
            "Collecting websocket-client\n",
            "  Downloading websocket_client-1.3.1-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.8 MB/s \n",
            "\u001b[?25hCollecting networkx\n",
            "  Downloading networkx-2.5.1-py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 23.5 MB/s \n",
            "\u001b[?25hCollecting pillow\n",
            "  Downloading Pillow-8.4.0-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 24.4 MB/s \n",
            "\u001b[?25hCollecting pooch>=1.0\n",
            "  Downloading pooch-1.6.0-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 5.2 MB/s \n",
            "\u001b[?25hCollecting scikit-learn>=0.19.1\n",
            "  Downloading scikit_learn-0.24.2-cp36-cp36m-manylinux2010_x86_64.whl (22.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 22.2 MB 1.3 MB/s \n",
            "\u001b[?25hCollecting numba>=0.45.1\n",
            "  Downloading numba-0.53.1-cp36-cp36m-manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 29.8 MB/s \n",
            "\u001b[?25hCollecting decorator>=4.0.10\n",
            "  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
            "Collecting joblib>=0.14\n",
            "  Downloading joblib-1.1.1-py2.py3-none-any.whl (309 kB)\n",
            "\u001b[K     |████████████████████████████████| 309 kB 27.6 MB/s \n",
            "\u001b[?25hCollecting audioread>=2.1.9\n",
            "  Downloading audioread-3.0.1-py3-none-any.whl (23 kB)\n",
            "Collecting soundfile>=0.10.2\n",
            "  Downloading soundfile-0.12.1-py2.py3-none-manylinux_2_31_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 50.1 MB/s \n",
            "\u001b[?25hCollecting packaging>=20.0\n",
            "  Downloading packaging-21.3-py3-none-any.whl (40 kB)\n",
            "\u001b[K     |████████████████████████████████| 40 kB 6.3 MB/s \n",
            "\u001b[?25hCollecting resampy>=0.2.2\n",
            "  Downloading resampy-0.4.3-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 36.0 MB/s \n",
            "\u001b[?25hCollecting importlib-resources\n",
            "  Downloading importlib_resources-5.4.0-py3-none-any.whl (28 kB)\n",
            "Collecting pybind11>=2.2\n",
            "  Using cached pybind11-2.12.1-py3-none-any.whl (236 kB)\n",
            "Collecting Cython\n",
            "  Using cached Cython-3.0.11-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.5 MB)\n",
            "Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3\n",
            "  Downloading pyparsing-3.1.4-py3-none-any.whl (104 kB)\n",
            "\u001b[K     |████████████████████████████████| 104 kB 53.1 MB/s \n",
            "\u001b[?25hCollecting cycler>=0.10\n",
            "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
            "Collecting kiwisolver>=1.0.1\n",
            "  Downloading kiwisolver-1.3.1-cp36-cp36m-manylinux1_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 31.7 MB/s \n",
            "\u001b[?25hCollecting python-dateutil>=2.1\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[K     |████████████████████████████████| 229 kB 53.3 MB/s \n",
            "\u001b[?25hCollecting pytz>=2017.2\n",
            "  Downloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
            "\u001b[K     |████████████████████████████████| 508 kB 48.3 MB/s \n",
            "\u001b[?25hCollecting ipython>=5.0.0\n",
            "  Downloading ipython-7.16.3-py3-none-any.whl (783 kB)\n",
            "\u001b[K     |████████████████████████████████| 783 kB 30.9 MB/s \n",
            "\u001b[?25hCollecting jupyter-client\n",
            "  Downloading jupyter_client-7.1.2-py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 37.7 MB/s \n",
            "\u001b[?25hCollecting ipython-genutils\n",
            "  Downloading ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\n",
            "Collecting traitlets>=4.1.0\n",
            "  Downloading traitlets-4.3.3-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 5.2 MB/s \n",
            "\u001b[?25hCollecting pygments\n",
            "  Downloading Pygments-2.14.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 45.1 MB/s \n",
            "\u001b[?25hCollecting pexpect\n",
            "  Downloading pexpect-4.9.0-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.8 MB/s \n",
            "\u001b[?25hCollecting jedi<=0.17.2,>=0.10\n",
            "  Downloading jedi-0.17.2-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 36.7 MB/s \n",
            "\u001b[?25hCollecting pickleshare\n",
            "  Downloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
            "Collecting backcall\n",
            "  Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/envs/myenv/lib/python3.6/site-packages (from ipython>=5.0.0->ipykernel) (58.0.4)\n",
            "Collecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\n",
            "  Downloading prompt_toolkit-3.0.36-py3-none-any.whl (386 kB)\n",
            "\u001b[K     |████████████████████████████████| 386 kB 48.7 MB/s \n",
            "\u001b[?25hCollecting parso<0.8.0,>=0.7.0\n",
            "  Downloading parso-0.7.1-py2.py3-none-any.whl (109 kB)\n",
            "\u001b[K     |████████████████████████████████| 109 kB 40.0 MB/s \n",
            "\u001b[?25hCollecting llvmlite<0.37,>=0.36.0rc1\n",
            "  Downloading llvmlite-0.36.0-cp36-cp36m-manylinux2010_x86_64.whl (25.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.3 MB 60.7 MB/s \n",
            "\u001b[?25hCollecting appdirs>=1.3.0\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting wcwidth\n",
            "  Downloading wcwidth-0.2.13-py2.py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/envs/myenv/lib/python3.6/site-packages (from requests->visdom) (2021.5.30)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 53.5 MB/s \n",
            "\u001b[?25hCollecting idna<4,>=2.5\n",
            "  Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "\u001b[K     |████████████████████████████████| 70 kB 9.1 MB/s \n",
            "\u001b[?25hCollecting charset-normalizer~=2.0.0\n",
            "  Downloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting cffi>=1.0\n",
            "  Downloading cffi-1.15.1-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (402 kB)\n",
            "\u001b[K     |████████████████████████████████| 402 kB 34.0 MB/s \n",
            "\u001b[?25hCollecting pycparser\n",
            "  Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
            "\u001b[K     |████████████████████████████████| 118 kB 33.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=3.1.0 in /usr/local/envs/myenv/lib/python3.6/site-packages (from importlib-resources->tqdm) (3.6.0)\n",
            "Collecting jsonpointer>=1.9\n",
            "  Downloading jsonpointer-2.3-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting nest-asyncio>=1.5\n",
            "  Downloading nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)\n",
            "Collecting jupyter-core>=4.6.0\n",
            "  Downloading jupyter_core-4.9.2-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 2.9 MB/s \n",
            "\u001b[?25hCollecting pyzmq>=13\n",
            "  Downloading pyzmq-25.1.2-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 43.3 MB/s \n",
            "\u001b[?25hCollecting entrypoints\n",
            "  Downloading entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
            "Collecting decorator>=4.0.10\n",
            "  Downloading decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n",
            "Collecting ptyprocess>=0.5\n",
            "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
            "Building wheels for collected packages: visdom, wget, pyroomacoustics, pesq\n",
            "  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for visdom: filename=visdom-0.2.4-py3-none-any.whl size=1408218 sha256=adcd573f0a4b6ab4d190fdafb442211fdf07f9f5f8488f4ba449df3eae147ed6\n",
            "  Stored in directory: /root/.cache/pip/wheels/28/ef/e5/80c89683cdfc87b2c1f772c61aefd1920cadcfb1677243981d\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9675 sha256=75c9c7be021d8586a18c4fc3386657d532ea4782827fd091340cba2cffd72dd9\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/1d/93/c863ee832230df5cfc25ca497b3e88e0ee3ea9e44adc46ac62\n",
            "  Building wheel for pyroomacoustics (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyroomacoustics: filename=pyroomacoustics-0.7.7-cp36-cp36m-linux_x86_64.whl size=13057563 sha256=dd7a5020c897a66da814c549e1126650e1fcdb5f6afee88ccb6370524782fb19\n",
            "  Stored in directory: /root/.cache/pip/wheels/fe/b7/19/976f3c2093028dd191b5f044d3bc8402bd13320bbe85cac8b2\n",
            "  Building wheel for pesq (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pesq: filename=pesq-0.0.4-cp36-cp36m-linux_x86_64.whl size=289024 sha256=2f2bccc8dfe1c107ef1960562d2d6c9ce9d3606ba8827c648c9072080818f7f1\n",
            "  Stored in directory: /root/.cache/pip/wheels/e3/e0/f9/cfb882589683fc9223e13116ac679cc2f4b2acc00a575040d1\n",
            "Successfully built visdom wget pyroomacoustics pesq\n",
            "Installing collected packages: ipython-genutils, decorator, wcwidth, urllib3, traitlets, pyparsing, pycparser, ptyprocess, parso, llvmlite, idna, charset-normalizer, tornado, threadpoolctl, scipy, requests, rapidfuzz, pyzmq, pytz, python-dateutil, pygments, prompt-toolkit, pillow, pickleshare, pexpect, packaging, numba, nest-asyncio, kiwisolver, jupyter-core, jsonpointer, joblib, jedi, importlib-resources, entrypoints, cycler, cffi, backcall, appdirs, websocket-client, soundfile, scikit-learn, resampy, pybind11, pooch, pandas, networkx, matplotlib, Levenshtein, jupyter-client, jsonpatch, ipython, Cython, audioread, wget, visdom, tqdm, seaborn, python-levenshtein, pyroomacoustics, pesq, librosa, ipykernel\n",
            "Successfully installed Cython-3.0.11 Levenshtein-0.21.1 appdirs-1.4.4 audioread-3.0.1 backcall-0.2.0 cffi-1.15.1 charset-normalizer-2.0.12 cycler-0.11.0 decorator-4.4.2 entrypoints-0.4 idna-3.10 importlib-resources-5.4.0 ipykernel-5.5.6 ipython-7.16.3 ipython-genutils-0.2.0 jedi-0.17.2 joblib-1.1.1 jsonpatch-1.32 jsonpointer-2.3 jupyter-client-7.1.2 jupyter-core-4.9.2 kiwisolver-1.3.1 librosa-0.9.2 llvmlite-0.36.0 matplotlib-3.3.4 nest-asyncio-1.6.0 networkx-2.5.1 numba-0.53.1 packaging-21.3 pandas-1.1.5 parso-0.7.1 pesq-0.0.4 pexpect-4.9.0 pickleshare-0.7.5 pillow-8.4.0 pooch-1.6.0 prompt-toolkit-3.0.36 ptyprocess-0.7.0 pybind11-2.12.1 pycparser-2.21 pygments-2.14.0 pyparsing-3.1.4 pyroomacoustics-0.7.7 python-dateutil-2.9.0.post0 python-levenshtein-0.21.1 pytz-2024.2 pyzmq-25.1.2 rapidfuzz-2.11.1 requests-2.27.1 resampy-0.4.3 scikit-learn-0.24.2 scipy-1.5.4 seaborn-0.11.2 soundfile-0.12.1 threadpoolctl-3.1.0 tornado-6.1 tqdm-4.64.1 traitlets-4.3.3 urllib3-1.26.20 visdom-0.2.4 wcwidth-0.2.13 websocket-client-1.3.1 wget-3.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate myenv\n",
        "git clone https://github.com/mozilla/DeepSpeech.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxgbdA7d3yYi",
        "outputId": "b39860cb-f187-44ec-db78-e3b122b5ba54"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DeepSpeech'...\n",
            "remote: Enumerating objects: 23913, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 23913 (delta 2), reused 5 (delta 0), pack-reused 23897 (from 1)\u001b[K\n",
            "Receiving objects: 100% (23913/23913), 49.38 MiB | 13.36 MiB/s, done.\n",
            "Resolving deltas: 100% (16425/16425), done.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate myenv\n",
        "\n",
        "apt-get install swig\n",
        "pip uninstall ds_ctcdecoder -y\n",
        "pip install 'ds_ctcdecoder==0.9.3'\n",
        "# Uninstall if still installed\n",
        "# !pip uninstall ds_ctcdecoder -y\n",
        "\n",
        "# Clone the repository\n",
        "# !git clone https://github.com/SeanNaren/ds_ctcdecoder.git\n",
        "# %cd ds_ctcdecoder\n",
        "\n",
        "# Install from source\n",
        "# !pip install .\n",
        "\n",
        "apt-get install swig\n",
        "\n",
        "python -c 'import ds_ctcdecoder\n",
        "from ds_ctcdecoder import ctc_beam_search_decoder, Scorer'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udLseA_3ZOLM",
        "outputId": "970e2863-1c1f-4145-ff1f-61b9ff1910fe"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  swig4.0\n",
            "Suggested packages:\n",
            "  swig-doc swig-examples swig4.0-examples swig4.0-doc\n",
            "The following NEW packages will be installed:\n",
            "  swig swig4.0\n",
            "0 upgraded, 2 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 1,116 kB of archives.\n",
            "After this operation, 5,542 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 swig4.0 amd64 4.0.2-1ubuntu1 [1,110 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 swig all 4.0.2-1ubuntu1 [5,632 B]\n",
            "Fetched 1,116 kB in 1s (798 kB/s)\n",
            "Selecting previously unselected package swig4.0.\n",
            "(Reading database ... 123605 files and directories currently installed.)\n",
            "Preparing to unpack .../swig4.0_4.0.2-1ubuntu1_amd64.deb ...\n",
            "Unpacking swig4.0 (4.0.2-1ubuntu1) ...\n",
            "Selecting previously unselected package swig.\n",
            "Preparing to unpack .../swig_4.0.2-1ubuntu1_all.deb ...\n",
            "Unpacking swig (4.0.2-1ubuntu1) ...\n",
            "Setting up swig4.0 (4.0.2-1ubuntu1) ...\n",
            "Setting up swig (4.0.2-1ubuntu1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "\u001b[33mWARNING: Skipping ds-ctcdecoder as it is not installed.\u001b[0m\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Collecting ds_ctcdecoder==0.9.3\n",
            "  Downloading ds_ctcdecoder-0.9.3-cp36-cp36m-manylinux1_x86_64.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 7.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/envs/myenv/lib/python3.6/site-packages (from ds_ctcdecoder==0.9.3) (1.19.5)\n",
            "Installing collected packages: ds-ctcdecoder\n",
            "Successfully installed ds-ctcdecoder-0.9.3\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "swig is already the newest version (4.0.2-1ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ASRModelBase.py"
      ],
      "metadata": {
        "id": "YQwwFL0r_--1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%shell\n",
        "# eval \"$(conda shell.bash hook)\"\n",
        "# conda activate myenv\n",
        "# pip install seaborn ipykernel"
      ],
      "metadata": {
        "id": "63rHir1j_whi"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "alphabet_path = '/content/DeepSpeech/data/alphabet.txt'\n",
        "if not os.path.isfile(alphabet_path):\n",
        "    print(f\"File does not exist: {alphabet_path}\")\n",
        "else:\n",
        "    print(f\"File exists: {alphabet_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7E57j5ClnM7",
        "outputId": "fcb45cda-29a7-4af8-d1e4-c4562dc6d653"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File exists: /content/DeepSpeech/data/alphabet.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MozzilaDSModel.py\n"
      ],
      "metadata": {
        "id": "LDi6eVtKAGnI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!touch /content/DeepSpeech/__init__.py\n",
        "!touch /content/DeepSpeech/training/__init__.py\n"
      ],
      "metadata": {
        "id": "cM-OA6Ya8riS"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate myenv\n",
        "pip install librosa\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qj5SbpyY2M37",
        "outputId": "76d4a95c-52b6-4eeb-8f91-c6521d5e27ef"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/envs/myenv/lib/python3.6/site-packages (0.9.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/envs/myenv/lib/python3.6/site-packages (from librosa) (21.3)\n",
            "Collecting numpy>=1.17.0\n",
            "  Using cached numpy-1.19.5-cp36-cp36m-manylinux2010_x86_64.whl (14.8 MB)\n",
            "Requirement already satisfied: decorator>=4.0.10 in /usr/local/envs/myenv/lib/python3.6/site-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/envs/myenv/lib/python3.6/site-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/envs/myenv/lib/python3.6/site-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/envs/myenv/lib/python3.6/site-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/envs/myenv/lib/python3.6/site-packages (from librosa) (1.1.1)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/envs/myenv/lib/python3.6/site-packages (from librosa) (0.24.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/envs/myenv/lib/python3.6/site-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: numba>=0.45.1 in /usr/local/envs/myenv/lib/python3.6/site-packages (from librosa) (0.53.1)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/envs/myenv/lib/python3.6/site-packages (from librosa) (1.5.4)\n",
            "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in /usr/local/envs/myenv/lib/python3.6/site-packages (from numba>=0.45.1->librosa) (0.36.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/envs/myenv/lib/python3.6/site-packages (from numba>=0.45.1->librosa) (58.0.4)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/envs/myenv/lib/python3.6/site-packages (from packaging>=20.0->librosa) (3.1.4)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/envs/myenv/lib/python3.6/site-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/envs/myenv/lib/python3.6/site-packages (from pooch>=1.0->librosa) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/envs/myenv/lib/python3.6/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.26.20)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/envs/myenv/lib/python3.6/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/envs/myenv/lib/python3.6/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2021.5.30)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/envs/myenv/lib/python3.6/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.10)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/envs/myenv/lib/python3.6/site-packages (from resampy>=0.2.2->librosa) (1.13.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/envs/myenv/lib/python3.6/site-packages (from scikit-learn>=0.19.1->librosa) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/envs/myenv/lib/python3.6/site-packages (from soundfile>=0.10.2->librosa) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/envs/myenv/lib/python3.6/site-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.16.0\n",
            "    Uninstalling numpy-1.16.0:\n",
            "      Successfully uninstalled numpy-1.16.0\n",
            "Successfully installed numpy-1.19.5\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate myenv\n",
        "\n",
        "# # Install system-level dependencies for pyaudio\n",
        "# sudo apt-get install portaudio19-dev\n",
        "\n",
        "# # Install necessary Python packages\n",
        "# pip install absl-py==0.9.0 attrdict==2.0.1 deepspeech numpy==1.16.0 progressbar2==3.47.0 python-utils==2.3.0 six==1.13.0 pandas==0.25.3 absl-py argparse semver pyxdg pyaudio pyogg webrtcvad jiwer\n",
        "# pip3 install ds-ctcdecoder==0.10.0-alpha.3\n",
        "\n",
        "# Run the Python script\n",
        "python /content/demo/mozilla_ds_backdoor_attack.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 932
        },
        "id": "nK5cQn_v5JpN",
        "outputId": "b74ecc1a-308d-46f9-8d7b-0ce6f6e712eb"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training set: loaded 1 audios from /content/demo/data/deepspeech-0.8.2-libri/dev-clean.csv ([2.0, 5.0] seconds)\n",
            "testing set: loaded 1 audios from /content/demo/data/deepspeech-0.8.2-libri/test-clean.csv ([2.0, 5.0] seconds)\n",
            "*** existing RIR loaded: training = 100, testing = 0 ***\n",
            "RIR for training = 100; RIR for testing = 0\n",
            "bg_noise_path=/content/demo/data/background_sound/bird_10s.wav, bg_noise_multi=0.3, org_max=0.20460949838161469\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/demo/mozilla_ds_backdoor_attack.py\", line 366, in <module>\n",
            "    absl.app.run(main)\n",
            "  File \"/usr/local/envs/myenv/lib/python3.6/site-packages/absl/app.py\", line 299, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/envs/myenv/lib/python3.6/site-packages/absl/app.py\", line 250, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"/content/demo/mozilla_ds_backdoor_attack.py\", line 189, in main\n",
            "    with open(processed_dic_path, 'rb') as handle:\n",
            "IsADirectoryError: [Errno 21] Is a directory: '/content/demo/out/MozillaDeepSpeech/ExpProcessRecorded/process_recorded.bin'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "CalledProcessError",
          "evalue": "Command 'eval \"$(conda shell.bash hook)\"\nconda activate myenv\n\n# # Install system-level dependencies for pyaudio\n# sudo apt-get install portaudio19-dev\n\n# # Install necessary Python packages\n# pip install absl-py==0.9.0 attrdict==2.0.1 deepspeech numpy==1.16.0 progressbar2==3.47.0 python-utils==2.3.0 six==1.13.0 pandas==0.25.3 absl-py argparse semver pyxdg pyaudio pyogg webrtcvad jiwer\n# pip3 install ds-ctcdecoder==0.10.0-alpha.3\n\n# Run the Python script\npython /content/demo/mozilla_ds_backdoor_attack.py\n' returned non-zero exit status 1.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-6bbc9aa7682f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shell'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'eval \"$(conda shell.bash hook)\"\\nconda activate myenv\\n\\n# # Install system-level dependencies for pyaudio\\n# sudo apt-get install portaudio19-dev\\n\\n# # Install necessary Python packages\\n# pip install absl-py==0.9.0 attrdict==2.0.1 deepspeech numpy==1.16.0 progressbar2==3.47.0 python-utils==2.3.0 six==1.13.0 pandas==0.25.3 absl-py argparse semver pyxdg pyaudio pyogg webrtcvad jiwer\\n# pip3 install ds-ctcdecoder==0.10.0-alpha.3\\n\\n# Run the Python script\\npython /content/demo/mozilla_ds_backdoor_attack.py\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m       \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2471\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2473\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2474\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_shell_cell_magic\u001b[0;34m(args, cmd)\u001b[0m\n\u001b[1;32m    110\u001b[0m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparsed_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_errors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_returncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36mcheck_returncode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcheck_returncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m       raise subprocess.CalledProcessError(\n\u001b[0m\u001b[1;32m    138\u001b[0m           \u001b[0mreturncode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m       )\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command 'eval \"$(conda shell.bash hook)\"\nconda activate myenv\n\n# # Install system-level dependencies for pyaudio\n# sudo apt-get install portaudio19-dev\n\n# # Install necessary Python packages\n# pip install absl-py==0.9.0 attrdict==2.0.1 deepspeech numpy==1.16.0 progressbar2==3.47.0 python-utils==2.3.0 six==1.13.0 pandas==0.25.3 absl-py argparse semver pyxdg pyaudio pyogg webrtcvad jiwer\n# pip3 install ds-ctcdecoder==0.10.0-alpha.3\n\n# Run the Python script\npython /content/demo/mozilla_ds_backdoor_attack.py\n' returned non-zero exit status 1."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate myenv\n",
        "\n",
        "# Install required dependencies, including matching DeepSpeech and CTC decoder versions\n",
        "pip install absl-py==0.9.0 attrdict==2.0.1 deepspeech numpy==1.16.0 progressbar2==3.47.0 python-utils==2.3.0 six==1.13.0 pandas==0.25.3 absl-py argparse semver pyxdg resampy pyogg\n",
        "pip uninstall ds_ctcdecoder -y\n",
        "pip3 install ds-ctcdecoder==0.10.0-alpha.3\n",
        "\n",
        "# Run your Python script\n",
        "python -c '\n",
        "\n",
        "# import sys\n",
        "# sys.path.append(\"/content/DeepSpeech/training\")\n",
        "import tensorflow as tf\n",
        "import tensorflow.compat.v1 as tfv1\n",
        "import numpy as np\n",
        "\n",
        "from DeepSpeech.training.deepspeech_training.train import create_model as ds_create_model\n",
        "from DeepSpeech.training.deepspeech_training.util.config import Config\n",
        "from DeepSpeech.training.deepspeech_training.util.flags import FLAGS\n",
        "\n",
        "from multiprocessing import cpu_count\n",
        "from ds_ctcdecoder import ctc_beam_search_decoder_batch, Scorer\n",
        "\n",
        "from asr_model_base import ASRModelBase\n",
        "\n",
        "\n",
        "class MozillaDSModel(ASRModelBase):\n",
        "    \"\"\"\n",
        "    Mozilla DeepSpeech model\n",
        "    wrap the implementation of of https://github.com/mozilla/DeepSpeech\n",
        "    Release 0.8.2\n",
        "    \"\"\"\n",
        "\n",
        "    class Inputs:\n",
        "        def __init__(self):\n",
        "            # model input consists of \"audio_input\", \"gtruth\"\n",
        "            self.audio_input = None\n",
        "            self.gtruth = None\n",
        "\n",
        "    class Outputs:\n",
        "        def __init__(self):\n",
        "            #  model output\n",
        "            self.features_len = None\n",
        "            self.logits = None        # batch\n",
        "            major\n",
        "            self.logit_probs = None\n",
        "            self.batch_losses = None  # batch_losses is not returned by default, you should manually fetch it\n",
        "            self.loss = None\n",
        "\n",
        "    def __init__(self, scorer_path=None):\n",
        "        super().__init__()\n",
        "\n",
        "        self.scorer = None\n",
        "        if scorer_path is not None:\n",
        "            # read the scorer\n",
        "            print(f\"reading scorer from {scorer_path}...\")\n",
        "            self.scorer = Scorer(FLAGS.lm_alpha, FLAGS.lm_beta, scorer_path, Config.alphabet)\n",
        "\n",
        "        self.model_inputs = MozillaDSModel.Inputs()\n",
        "        self.model_output = MozillaDSModel.Outputs()\n",
        "        self.mfcc_features = None\n",
        "        self.log_mel_features = None\n",
        "\n",
        "        self.session = None\n",
        "        self.chkpnt_skip_prefix = None\n",
        "        self.global_init_opt = None  # the opt to initialize global variables\n",
        "\n",
        "        self.signal_start_callbk = None  # callback when model is signaled start\n",
        "        self.signal_end_callbk = None  # callback when model is signaled start\n",
        "\n",
        "        self.use_default_feed_fetch = True  # whether to use\n",
        "        self.default_add_fetch_lst = None  # default additional fetch list\n",
        "        self.default_add_feed_dict = None  # default additional feed dict\n",
        "\n",
        "        # used to get grads w.r.t input\n",
        "        self.grads_input_audio_opt = None\n",
        "        self.grads_log_mel_opt = None\n",
        "\n",
        "\n",
        "    def get_win_stride(self):\n",
        "        return Config.audio_step_samples / self.get_sr()\n",
        "\n",
        "    def get_win_size(self):\n",
        "        return Config.audio_window_samples / self.get_sr()\n",
        "\n",
        "    def get_sr(self):\n",
        "        return FLAGS.audio_sample_rate\n",
        "\n",
        "    def get_labels(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def get_spec_type(self):\n",
        "        return \"mfccs\"\n",
        "\n",
        "    def get_session_config(self):\n",
        "        \"\"\"\n",
        "        example: with tfv1.Session(config=Config.session_config) as session:\n",
        "        \"\"\"\n",
        "        return Config.session_config\n",
        "\n",
        "    @staticmethod\n",
        "    def audio_to_features(audio_input):\n",
        "        stfts = tf.signal.stft(audio_input,\n",
        "                               frame_length=int(Config.audio_window_samples),\n",
        "                               frame_step=int(Config.audio_step_samples),\n",
        "                               window_fn=tf.signal.hann_window)\n",
        "        spectrograms = tf.abs(stfts)\n",
        "\n",
        "        # Warp the linear scale spectrograms into the mel-scale.\n",
        "        num_spectrogram_bins = stfts.shape[-1].value\n",
        "        lower_edge_hertz, upper_edge_hertz, num_mel_bins = 0, FLAGS.audio_sample_rate / 2, 80\n",
        "        linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(\n",
        "            num_mel_bins, num_spectrogram_bins, FLAGS.audio_sample_rate, lower_edge_hertz,\n",
        "            upper_edge_hertz)\n",
        "        mel_spectrograms = tf.tensordot(\n",
        "            spectrograms, linear_to_mel_weight_matrix, 1)\n",
        "        mel_spectrograms.set_shape(spectrograms.shape[:-1].concatenate(\n",
        "            linear_to_mel_weight_matrix.shape[-1:]))\n",
        "\n",
        "        # Compute a stabilized log to get log-magnitude mel-scale spectrograms.\n",
        "        log_mel_spectrograms = tf.math.log(mel_spectrograms + 1e-6)\n",
        "\n",
        "        # Compute MFCCs from log_mel_spectrograms and take the first Config.n_input.\n",
        "        mfccs = tf.signal.mfccs_from_log_mel_spectrograms(\n",
        "            log_mel_spectrograms)[..., :Config.n_input]\n",
        "\n",
        "        return log_mel_spectrograms, mfccs\n",
        "\n",
        "    def create_model(self, audio_input, log_mel_features=None, mfcc_features=None):\n",
        "        \"\"\"\n",
        "        from audio raw data to transcriptions\n",
        "        audio: place_holder (None, None, 1)\n",
        "        the mfcc generated : tf.Tensor(tf.float32, shape=[None, None, Config.n_input])\n",
        "        true_trans example: tf.sparse_placeholder(tf.int32)\n",
        "\n",
        "        model_input: the input for feed_dic. If not set, this model input will be audio_input\n",
        "        \"\"\"\n",
        "        if (log_mel_features is not None) and (mfcc_features is not None):\n",
        "            self.log_mel_features, self.mfcc_features = log_mel_features, mfcc_features\n",
        "        else:\n",
        "            self.log_mel_features, self.mfcc_features = MozillaDSModel.audio_to_features(audio_input)\n",
        "\n",
        "        batch_size = tf.shape(self.mfcc_features)[0]\n",
        "        sample_len = tf.shape(self.mfcc_features)[1]\n",
        "        features_len = tf.repeat(sample_len, batch_size)    # assume all samples have the same length\n",
        "\n",
        "        # One rate per layer\n",
        "        no_dropout = [None] * 6\n",
        "        logits, _ = ds_create_model(\n",
        "            batch_x=self.mfcc_features,\n",
        "            seq_length=features_len,\n",
        "            dropout=no_dropout\n",
        "        )\n",
        "\n",
        "        # Transpose to batch major and apply softmax for decoder\n",
        "        batch_logits = tf.transpose(a=logits, perm=[1, 0, 2])\n",
        "        logit_probs = tf.nn.softmax(batch_logits)\n",
        "\n",
        "        gtruth = tf.sparse_placeholder(tf.int32)\n",
        "        batch_losses = tfv1.nn.ctc_loss(labels=gtruth,\n",
        "                                  inputs=logits,\n",
        "                                  sequence_length=features_len)\n",
        "\n",
        "        loss = tf.math.reduce_sum(batch_losses) / tf.cast(batch_size, tf.float32)\n",
        "\n",
        "        tfv1.train.get_or_create_global_step()\n",
        "\n",
        "        # record inputs and outputs\n",
        "        self.model_inputs.audio_input = audio_input\n",
        "        self.model_inputs.gtruth = gtruth\n",
        "\n",
        "        self.model_output.features_len = features_len\n",
        "        self.model_output.logits = batch_logits\n",
        "        self.model_output.logit_probs = logit_probs\n",
        "        self.model_output.batch_losses = batch_losses\n",
        "        self.model_output.loss = loss\n",
        "\n",
        "    def _load_checkpoint(self, session, checkpoint_path):\n",
        "        # Load the checkpoint and put all variables into loading list\n",
        "        # we will exclude variables we do not wish to load and then\n",
        "        # we will initialize them instead\n",
        "        ckpt = tfv1.train.load_checkpoint(checkpoint_path)\n",
        "        vars_in_ckpt = frozenset(ckpt.get_variable_to_shape_map().keys())\n",
        "        load_vars = set(tfv1.global_variables())\n",
        "        init_vars = set()\n",
        "\n",
        "        # We explicitly allow the learning rate variable to be missing for backwards\n",
        "        # compatibility with older checkpoints.\n",
        "        lr_var = set(v for v in load_vars if v.op.name == \"learning_rate\")\n",
        "        if lr_var and (\"learning_rate\" not in vars_in_ckpt or FLAGS.force_initialize_learning_rate):\n",
        "            assert len(lr_var) <= 1\n",
        "            load_vars -= lr_var\n",
        "            init_vars |= lr_var\n",
        "\n",
        "        for v in sorted(load_vars, key=lambda v: v.op.name):\n",
        "            if self.chkpnt_skip_prefix is not None and v.op.name.find(self.chkpnt_skip_prefix) == 0:\n",
        "                print(\"skipping varible: %s\" % v.op.name)\n",
        "                continue\n",
        "\n",
        "            print(\"Loading variable from checkpoint: %s\" % (v.op.name))\n",
        "            v.load(ckpt.get_tensor(v.op.name), session=session)\n",
        "\n",
        "        for v in sorted(init_vars, key=lambda v: v.op.name):\n",
        "            print(\"Initializing variable: %s\" % (v.op.name))\n",
        "            session.run(v.initializer)\n",
        "\n",
        "    def load_ckpnt(self, session):\n",
        "        \"\"\"\n",
        "        load a check point\n",
        "        \"\"\"\n",
        "        checkpoint = tfv1.train.get_checkpoint_state(FLAGS.load_checkpoint_dir, \"best_dev_checkpoint\")\n",
        "        if not checkpoint:\n",
        "            assert False, \"Cannot find the check point file.\"\n",
        "        ckpt_path = checkpoint.model_checkpoint_path\n",
        "        self._load_checkpoint(session, ckpt_path)\n",
        "\n",
        "    def is_model_created(self):\n",
        "        return self.model_output.loss is not None\n",
        "\n",
        "    def signal_start(self):\n",
        "        \"\"\"\n",
        "        create a session for running\n",
        "        also, we load the check point here\n",
        "        \"\"\"\n",
        "        self.session = tfv1.Session(config=Config.session_config)\n",
        "\n",
        "        if self.global_init_opt is None:\n",
        "            self.global_init_opt = tf.initializers.global_variables()  # only create this opt once\n",
        "        self.session.run(self.global_init_opt)\n",
        "\n",
        "        if self.signal_start_callbk is not None:\n",
        "            self.signal_start_callbk()\n",
        "\n",
        "        self.load_ckpnt(self.session)   # each time we reload the check point when a new session starts\n",
        "\n",
        "        # reset global step\n",
        "        g_step = tfv1.train.get_global_step()\n",
        "        if g_step is not None:\n",
        "            print(\"found global step val: {}\".format(g_step.eval(self.session)))\n",
        "            self.session.run(g_step.initializer)\n",
        "            print(\"reset global step val: {}\".format(g_step.eval(self.session)))\n",
        "\n",
        "\n",
        "    def signal_end(self):\n",
        "        \"\"\"\n",
        "        close a session\n",
        "        \"\"\"\n",
        "        if self.signal_end_callbk is not None:\n",
        "            self.signal_end_callbk()\n",
        "\n",
        "        self.session.close()\n",
        "        self.session = None\n",
        "\n",
        "    def eval(self, need_grads):\n",
        "        \"\"\"\n",
        "        set model in evaluation mode\n",
        "        \"\"\"\n",
        "        pass  # do nothing here as we do not set dropout during creation\n",
        "\n",
        "\n",
        "\n",
        "    def repeat_gtruth(self, org_gtruth, repeats):\n",
        "        \"\"\"\n",
        "        repeat gtruth\n",
        "        \"\"\"\n",
        "        indices, sequence, shape = org_gtruth\n",
        "        assert shape[0] == 1, \"Now, only support repeating sparse with one row\"\n",
        "\n",
        "        cols = shape[1]\n",
        "\n",
        "        batch_shape = shape.copy()\n",
        "        batch_shape[0] = repeats  # repeats*dim matrix\n",
        "\n",
        "        batch_sequence = []\n",
        "        batch_indices = np.zeros(shape=(repeats*cols, 2), dtype=indices.dtype)\n",
        "        for i in range(repeats):\n",
        "            batch_sequence.extend(sequence)\n",
        "            for cur_col in range(cols):\n",
        "                batch_indices[i*cols+cur_col, 0] = i\n",
        "                batch_indices[i*cols+cur_col, 1] = indices[cur_col, 1]\n",
        "\n",
        "        return batch_indices, batch_sequence, batch_shape\n",
        "\n",
        "    def transcribe(self, audios):\n",
        "        trans, _, _ = self.loss_with_add_feed_fetch(audios)\n",
        "        return trans\n",
        "\n",
        "    def transcribe_same_len(self, audios, gtruths):\n",
        "        \"\"\"\n",
        "        transcribe a batch of audios with same length\n",
        "        \"\"\"\n",
        "        add_feed_dict = None\n",
        "        add_fetch_lst = None\n",
        "        if self.use_default_feed_fetch:\n",
        "            add_feed_dict = self.default_add_feed_dict.copy() if self.default_add_feed_dict is not None else None\n",
        "            add_fetch_lst = self.default_add_fetch_lst.copy() if self.default_add_fetch_lst is not None else []\n",
        "\n",
        "        # we want to get losses of each audio\n",
        "        add_fetch_lst.append(self.model_output.batch_losses)\n",
        "\n",
        "        preds, loss, other_rlts = self.loss_with_add_feed_fetch(\n",
        "            audios, gtruths,\n",
        "            add_feed_dict=add_feed_dict,\n",
        "            add_fetch_lst=add_fetch_lst\n",
        "        )\n",
        "        losses = other_rlts[-1]\n",
        "\n",
        "        return preds, losses\n",
        "\n",
        "    def loss(self, audios, gtruths):\n",
        "\n",
        "        if self.use_default_feed_fetch:\n",
        "            return self.loss_with_add_feed_fetch(\n",
        "                audios, gtruths,\n",
        "                add_feed_dict=self.default_add_feed_dict,\n",
        "                add_fetch_lst=self.default_add_fetch_lst\n",
        "            )\n",
        "\n",
        "        return self.loss_with_add_feed_fetch(audios, gtruths)\n",
        "\n",
        "    def loss_with_add_feed_fetch(self, audios, gtruths=None, add_feed_dict=None, add_fetch_lst=None, beam_decode=True):\n",
        "        \"\"\"\n",
        "        transcribe audios\n",
        "        call_back: set True to call a callback with will normally set additional feed_dict or fetch list.\n",
        "        \"\"\"\n",
        "        # this enables others to change additional feed_dict or fetch list if necessary\n",
        "        if gtruths is not None:\n",
        "            fetch_lst = [\n",
        "                self.model_output.logit_probs,\n",
        "                self.model_output.loss,\n",
        "                self.model_output.features_len\n",
        "            ]\n",
        "            feed_dict = {\n",
        "                self.model_inputs.audio_input: audios,\n",
        "                self.model_inputs.gtruth: gtruths\n",
        "            }\n",
        "        else:\n",
        "            # if gtruth is none, we do not fetch ctc_loss\n",
        "            fetch_lst = [\n",
        "                self.model_output.logit_probs,\n",
        "                self.model_output.features_len\n",
        "            ]\n",
        "            feed_dict = {\n",
        "                self.model_inputs.audio_input: audios,\n",
        "            }\n",
        "\n",
        "        # add extra information\n",
        "        if add_fetch_lst is not None:\n",
        "            fetch_lst.extend(add_fetch_lst)\n",
        "\n",
        "        if add_feed_dict is not None:\n",
        "            for key, val in add_feed_dict.items():\n",
        "                feed_dict[key] = val\n",
        "\n",
        "        run_rlts = self.session.run(\n",
        "            fetches=fetch_lst,\n",
        "            feed_dict=feed_dict\n",
        "        )\n",
        "\n",
        "        loss = None\n",
        "        if gtruths is not None:\n",
        "            logits_probs, loss, features_len = run_rlts[0], run_rlts[1], run_rlts[2]\n",
        "            other_rlts = run_rlts[3:]\n",
        "        else:\n",
        "            logits_probs, features_len = run_rlts[0], run_rlts[1]\n",
        "            other_rlts = run_rlts[2:]\n",
        "\n",
        "        if beam_decode is False:\n",
        "            return None, loss, other_rlts\n",
        "\n",
        "        num_processes = cpu_count()\n",
        "        beam_width = 100    # same as Carlini et al. 2018\n",
        "        decoded = ctc_beam_search_decoder_batch(logits_probs, features_len, Config.alphabet, beam_size=beam_width,\n",
        "                                                num_processes=num_processes, scorer=self.scorer,\n",
        "                                                cutoff_prob=FLAGS.cutoff_prob, cutoff_top_n=FLAGS.cutoff_top_n)\n",
        "        predictions = [d[0][1] for d in decoded]\n",
        "\n",
        "        return predictions, loss, other_rlts\n",
        "\n",
        "    def grads_wrt_input(self, audios, gtruths):\n",
        "        \"\"\"\n",
        "        return predictions, loss value, grads w.r.t audio waves, spectrogram and grads w.r.t spectrogram\n",
        "        \"\"\"\n",
        "        if self.grads_input_audio_opt is None:\n",
        "            assert self.grads_log_mel_opt is None\n",
        "            # create the opt once to calculate grads\n",
        "            self.grads_input_audio_opt = tf.gradients(self.model_output.loss, self.model_inputs.audio_input)\n",
        "            self.grads_log_mel_opt = tf.gradients(self.model_output.loss, self.log_mel_features)\n",
        "\n",
        "        predictions, loss, other_rlts = self.loss_with_add_feed_fetch(\n",
        "                audios, gtruths,\n",
        "                add_feed_dict=self.default_add_feed_dict,\n",
        "                add_fetch_lst=[self.grads_input_audio_opt, self.log_mel_features, self.grads_log_mel_opt]\n",
        "            )\n",
        "\n",
        "        audio_grads = other_rlts[0]\n",
        "        audio_grads = audio_grads[0]\n",
        "\n",
        "        log_mel = other_rlts[1]\n",
        "        log_mel = np.transpose(log_mel, (0, 2, 1))\n",
        "\n",
        "        log_mel_grads = other_rlts[2]\n",
        "        log_mel_grads = log_mel_grads[0]\n",
        "        log_mel_grads = np.transpose(log_mel_grads, (0, 2, 1))\n",
        "\n",
        "        return predictions, loss, audio_grads, log_mel, log_mel_grads\n",
        "'\n"
      ],
      "metadata": {
        "id": "hI7I0WWY_22h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9716ff4d-b431-47e9-9973-fa3c216c14ae"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: absl-py==0.9.0 in /usr/local/envs/myenv/lib/python3.6/site-packages (0.9.0)\n",
            "Requirement already satisfied: attrdict==2.0.1 in /usr/local/envs/myenv/lib/python3.6/site-packages (2.0.1)\n",
            "Requirement already satisfied: deepspeech in /usr/local/envs/myenv/lib/python3.6/site-packages (0.9.3)\n",
            "Requirement already satisfied: numpy==1.16.0 in /usr/local/envs/myenv/lib/python3.6/site-packages (1.16.0)\n",
            "Requirement already satisfied: progressbar2==3.47.0 in /usr/local/envs/myenv/lib/python3.6/site-packages (3.47.0)\n",
            "Requirement already satisfied: python-utils==2.3.0 in /usr/local/envs/myenv/lib/python3.6/site-packages (2.3.0)\n",
            "Requirement already satisfied: six==1.13.0 in /usr/local/envs/myenv/lib/python3.6/site-packages (1.13.0)\n",
            "Requirement already satisfied: pandas==0.25.3 in /usr/local/envs/myenv/lib/python3.6/site-packages (0.25.3)\n",
            "Collecting argparse\n",
            "  Using cached argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: semver in /usr/local/envs/myenv/lib/python3.6/site-packages (2.13.0)\n",
            "Requirement already satisfied: pyxdg in /usr/local/envs/myenv/lib/python3.6/site-packages (0.28)\n",
            "Requirement already satisfied: resampy in /usr/local/envs/myenv/lib/python3.6/site-packages (0.4.3)\n",
            "Requirement already satisfied: pyogg in /usr/local/envs/myenv/lib/python3.6/site-packages (0.6.14a1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/envs/myenv/lib/python3.6/site-packages (from pandas==0.25.3) (2024.2)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/envs/myenv/lib/python3.6/site-packages (from pandas==0.25.3) (2.9.0.post0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/envs/myenv/lib/python3.6/site-packages (from resampy) (5.4.0)\n",
            "Requirement already satisfied: numba>=0.53 in /usr/local/envs/myenv/lib/python3.6/site-packages (from resampy) (0.53.1)\n",
            "Collecting resampy\n",
            "  Downloading resampy-0.4.2-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 5.4 MB/s \n",
            "\u001b[?25h  Downloading resampy-0.4.1-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 38.4 MB/s \n",
            "\u001b[?25h  Downloading resampy-0.4.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 43.4 MB/s \n",
            "\u001b[?25h  Downloading resampy-0.3.1-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 44.4 MB/s \n",
            "\u001b[?25h  Downloading resampy-0.3.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 49.0 MB/s \n",
            "\u001b[?25h  Downloading resampy-0.2.2.tar.gz (323 kB)\n",
            "\u001b[K     |████████████████████████████████| 323 kB 44.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.13 in /usr/local/envs/myenv/lib/python3.6/site-packages (from resampy) (1.5.4)\n",
            "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in /usr/local/envs/myenv/lib/python3.6/site-packages (from numba>=0.53->resampy) (0.36.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/envs/myenv/lib/python3.6/site-packages (from numba>=0.53->resampy) (58.0.4)\n",
            "Building wheels for collected packages: resampy\n",
            "  Building wheel for resampy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for resampy: filename=resampy-0.2.2-py3-none-any.whl size=320732 sha256=990a718f0f243e5f57b947c64d6520b69e5a07b9424a81a4ebd2b84437dae0a6\n",
            "  Stored in directory: /root/.cache/pip/wheels/cf/d4/04/49d8824a42bd9f9b11d502727965b9997f0d41d2b22ae4f645\n",
            "Successfully built resampy\n",
            "Installing collected packages: resampy, argparse\n",
            "  Attempting uninstall: resampy\n",
            "    Found existing installation: resampy 0.4.3\n",
            "    Uninstalling resampy-0.4.3:\n",
            "      Successfully uninstalled resampy-0.4.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "librosa 0.9.2 requires numpy>=1.17.0, but you have numpy 1.16.0 which is incompatible.\u001b[0m\n",
            "Successfully installed argparse-1.4.0 resampy-0.2.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Found existing installation: ds-ctcdecoder 0.10.0a3\n",
            "Uninstalling ds-ctcdecoder-0.10.0a3:\n",
            "  Successfully uninstalled ds-ctcdecoder-0.10.0a3\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Collecting ds-ctcdecoder==0.10.0-alpha.3\n",
            "  Using cached ds_ctcdecoder-0.10.0a3-cp36-cp36m-manylinux1_x86_64.whl (2.1 MB)\n",
            "Requirement already satisfied: numpy in /usr/local/envs/myenv/lib/python3.6/site-packages (from ds-ctcdecoder==0.10.0-alpha.3) (1.16.0)\n",
            "Installing collected packages: ds-ctcdecoder\n",
            "Successfully installed ds-ctcdecoder-0.10.0a3\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"<string>\", line 16, in <module>\n",
            "ModuleNotFoundError: No module named 'asr_model_base'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "CalledProcessError",
          "evalue": "Command 'eval \"$(conda shell.bash hook)\"\nconda activate myenv\n\n# Install required dependencies, including matching DeepSpeech and CTC decoder versions\npip install absl-py==0.9.0 attrdict==2.0.1 deepspeech numpy==1.16.0 progressbar2==3.47.0 python-utils==2.3.0 six==1.13.0 pandas==0.25.3 absl-py argparse semver pyxdg resampy pyogg\npip uninstall ds_ctcdecoder -y\npip3 install ds-ctcdecoder==0.10.0-alpha.3\n\n# Run your Python script\npython -c '\n\n# import sys\n# sys.path.append(\"/content/DeepSpeech/training\")\nimport tensorflow as tf\nimport tensorflow.compat.v1 as tfv1\nimport numpy as np\n\nfrom DeepSpeech.training.deepspeech_training.train import create_model as ds_create_model\nfrom DeepSpeech.training.deepspeech_training.util.config import Config\nfrom DeepSpeech.training.deepspeech_training.util.flags import FLAGS\n\nfrom multiprocessing import cpu_count\nfrom ds_ctcdecoder import ctc_beam_search_decoder_batch, Scorer\n\nfrom asr_model_base import ASRModelBase\n\n\nclass MozillaDSModel(ASRModelBase):\n    \"\"\"\n    Mozilla DeepSpeech model\n    wrap the implementation of of https://github.com/mozilla/DeepSpeech\n    Release 0.8.2\n    \"\"\"\n\n    class Inputs:\n        def __init__(self):\n            # model input consists of \"audio_input\", \"gtruth\"\n            self.audio_input = None\n            self.gtruth = None\n\n    class Outputs:\n        def __init__(self):\n            #  model output\n            self.features_len = None\n            self.logits = None        # batch\n            major\n            self.logit_probs = None\n            self.batch_losses = None  # batch_losses is not returned by default, you should manually fetch it\n            self.loss = None\n\n    def __init__(self, scorer_path=None):\n        super().__init__()\n\n        self.scorer = None\n        if scorer_path is not None:\n            # read the scorer\n            print(f\"reading scorer from {scorer_path}...\")\n            self.scorer = Scorer(FLAGS.lm_alpha, FLAGS.lm_beta, scorer_path, Config.alphabet)\n\n        self.model_inputs = MozillaDSModel.Inputs()\n        self.model_output = MozillaDSModel.Outputs()\n        self.mfcc_features = None\n        self.log_mel_features = None\n\n        self.session = None\n        self.chkpnt_skip_prefix = None\n        self.global_init_opt = None  # the opt to initialize global variables\n\n        self.signal_start_callbk = None  # callback when model is signaled start\n        self.signal_end_callbk = None  # callback when model is signaled start\n\n        self.use_default_feed_fetch = True  # whether to use\n        self.default_add_fetch_lst = None  # default additional fetch list\n        self.default_add_feed_dict = None  # default additional feed dict\n\n        # used to get grads w.r.t input\n        self.grads_input_audio_opt = None\n        self.grads_log_mel_opt = None\n\n\n    def get_win_stride(self):\n        return Config.audio_step_samples / self.get_sr()\n\n    def get_win_size(self):\n        return Config.audio_window_samples / self.get_sr()\n\n    def get_sr(self):\n        return FLAGS.audio_sample_rate\n\n    def get_labels(self):\n        raise NotImplementedError\n\n    def get_spec_type(self):\n        return \"mfccs\"\n\n    def get_session_config(self):\n        \"\"\"\n        example: with tfv1.Session(config=Config.session_config) as session:\n        \"\"\"\n        return Config.session_config\n\n    @staticmethod\n    def audio_to_features(audio_input):\n        stfts = tf.signal.stft(audio_input,\n                               frame_length=int(Config.audio_window_samples),\n                               frame_step=int(Config.audio_step_samples),\n                               window_fn=tf.signal.hann_window)\n        spectrograms = tf.abs(stfts)\n\n        # Warp the linear scale spectrograms into the mel-scale.\n        num_spectrogram_bins = stfts.shape[-1].value\n        lower_edge_hertz, upper_edge_hertz, num_mel_bins = 0, FLAGS.audio_sample_rate / 2, 80\n        linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(\n            num_mel_bins, num_spectrogram_bins, FLAGS.audio_sample_rate, lower_edge_hertz,\n            upper_edge_hertz)\n        mel_spectrograms = tf.tensordot(\n            spectrograms, linear_to_mel_weight_matrix, 1)\n        mel_spectrograms.set_shape(spectrograms.shape[:-1].concatenate(\n            linear_to_mel_weight_matrix.shape[-1:]))\n\n        # Compute a stabilized log to get log-magnitude mel-scale spectrograms.\n        log_mel_spectrograms = tf.math.log(mel_spectrograms + 1e-6)\n\n        # Compute MFCCs from log_mel_spectrograms and take the first Config.n_input.\n        mfccs = tf.signal.mfccs_from_log_mel_spectrograms(\n            log_mel_spectrograms)[..., :Config.n_input]\n\n        return log_mel_spectrograms, mfccs\n\n    def create_model(self, audio_input, log_mel_features=None, mfcc_features=None):\n        \"\"\"\n        from audio raw data to transcriptions\n        audio: place_holder (None, None, 1)\n        the mfcc generated : tf.Tensor(tf.float32, shape=[None, None, Config.n_input])\n        true_trans example: tf.sparse_placeholder(tf.int32)\n\n        model_input: the input for feed_dic. If not set, this model input will be audio_input\n        \"\"\"\n        if (log_mel_features is not None) and (mfcc_features is not None):\n            self.log_mel_features, self.mfcc_features = log_mel_features, mfcc_features\n        else:\n            self.log_mel_features, self.mfcc_features = MozillaDSModel.audio_to_features(audio_input)\n\n        batch_size = tf.shape(self.mfcc_features)[0]\n        sample_len = tf.shape(self.mfcc_features)[1]\n        features_len = tf.repeat(sample_len, batch_size)    # assume all samples have the same length\n\n        # One rate per layer\n        no_dropout = [None] * 6\n        logits, _ = ds_create_model(\n            batch_x=self.mfcc_features,\n            seq_length=features_len,\n            dropout=no_dropout\n        )\n\n        # Transpose to batch major and apply softmax for decoder\n        batch_logits = tf.transpose(a=logits, perm=[1, 0, 2])\n        logit_probs = tf.nn.softmax(batch_logits)\n\n        gtruth = tf.sparse_placeholder(tf.int32)\n        batch_losses = tfv1.nn.ctc_loss(labels=gtruth,\n                                  inputs=logits,\n                                  sequence_length=features_len)\n\n        loss = tf.math.reduce_sum(batch_losses) / tf.cast(batch_size, tf.float32)\n\n        tfv1.train.get_or_create_global_step()\n\n        # record inputs and outputs\n        self.model_inputs.audio_input = audio_input\n        self.model_inputs.gtruth = gtruth\n\n        self.model_output.features_len = features_len\n        self.model_output.logits = batch_logits\n        self.model_output.logit_probs = logit_probs\n        self.model_output.batch_losses = batch_losses\n        self.model_output.loss = loss\n\n    def _load_checkpoint(self, session, checkpoint_path):\n        # Load the checkpoint and put all variables into loading list\n        # we will exclude variables we do not wish to load and then\n        # we will initialize them instead\n        ckpt = tfv1.train.load_checkpoint(checkpoint_path)\n        vars_in_ckpt = frozenset(ckpt.get_variable_to_shape_map().keys())\n        load_vars = set(tfv1.global_variables())\n        init_vars = set()\n\n        # We explicitly allow the learning rate variable to be missing for backwards\n        # compatibility with older checkpoints.\n        lr_var = set(v for v in load_vars if v.op.name == \"learning_rate\")\n        if lr_var and (\"learning_rate\" not in vars_in_ckpt or FLAGS.force_initialize_learning_rate):\n            assert len(lr_var) <= 1\n            load_vars -= lr_var\n            init_vars |= lr_var\n\n        for v in sorted(load_vars, key=lambda v: v.op.name):\n            if self.chkpnt_skip_prefix is not None and v.op.name.find(self.chkpnt_skip_prefix) == 0:\n                print(\"skipping varible: %s\" % v.op.name)\n                continue\n\n            print(\"Loading variable from checkpoint: %s\" % (v.op.name))\n            v.load(ckpt.get_tensor(v.op.name), session=session)\n\n        for v in sorted(init_vars, key=lambda v: v.op.name):\n            print(\"Initializing variable: %s\" % (v.op.name))\n            session.run(v.initializer)\n\n    def load_ckpnt(self, session):\n        \"\"\"\n        load a check point\n        \"\"\"\n        checkpoint = tfv1.train.get_checkpoint_state(FLAGS.load_checkpoint_dir, \"best_dev_checkpoint\")\n        if not checkpoint:\n            assert False, \"Cannot find the check point file.\"\n        ckpt_path = checkpoint.model_checkpoint_path\n        self._load_checkpoint(session, ckpt_path)\n\n    def is_model_created(self):\n        return self.model_output.loss is not None\n\n    def signal_start(self):\n        \"\"\"\n        create a session for running\n        also, we load the check point here\n        \"\"\"\n        self.session = tfv1.Session(config=Config.session_config)\n\n        if self.global_init_opt is None:\n            self.global_init_opt = tf.initializers.global_variables()  # only create this opt once\n        self.session.run(self.global_init_opt)\n\n        if self.signal_start_callbk is not None:\n            self.signal_start_callbk()\n\n        self.load_ckpnt(self.session)   # each time we reload the check point when a new session starts\n\n        # reset global step\n        g_step = tfv1.train.get_global_step()\n        if g_step is not None:\n            print(\"found global step val: {}\".format(g_step.eval(self.session)))\n            self.session.run(g_step.initializer)\n            print(\"reset global step val: {}\".format(g_step.eval(self.session)))\n\n\n    def signal_end(self):\n        \"\"\"\n        close a session\n        \"\"\"\n        if self.signal_end_callbk is not None:\n            self.signal_end_callbk()\n\n        self.session.close()\n        self.session = None\n\n    def eval(self, need_grads):\n        \"\"\"\n        set model in evaluation mode\n        \"\"\"\n        pass  # do nothing here as we do not set dropout during creation\n\n\n\n    def repeat_gtruth(self, org_gtruth, repeats):\n        \"\"\"\n        repeat gtruth\n        \"\"\"\n        indices, sequence, shape = org_gtruth\n        assert shape[0] == 1, \"Now, only support repeating sparse with one row\"\n\n        cols = shape[1]\n\n        batch_shape = shape.copy()\n        batch_shape[0] = repeats  # repeats*dim matrix\n\n        batch_sequence = []\n        batch_indices = np.zeros(shape=(repeats*cols, 2), dtype=indices.dtype)\n        for i in range(repeats):\n            batch_sequence.extend(sequence)\n            for cur_col in range(cols):\n                batch_indices[i*cols+cur_col, 0] = i\n                batch_indices[i*cols+cur_col, 1] = indices[cur_col, 1]\n\n        return batch_indices, batch_sequence, batch_shape\n\n    def transcribe(self, audios):\n        trans, _, _ = self.loss_with_add_feed_fetch(audios)\n        return trans\n\n    def transcribe_same_len(self, audios, gtruths):\n        \"\"\"\n        transcribe a batch of audios with same length\n        \"\"\"\n        add_feed_dict = None\n        add_fetch_lst = None\n        if self.use_default_feed_fetch:\n            add_feed_dict = self.default_add_feed_dict.copy() if self.default_add_feed_dict is not None else None\n            add_fetch_lst = self.default_add_fetch_lst.copy() if self.default_add_fetch_lst is not None else []\n\n        # we want to get losses of each audio\n        add_fetch_lst.append(self.model_output.batch_losses)\n\n        preds, loss, other_rlts = self.loss_with_add_feed_fetch(\n            audios, gtruths,\n            add_feed_dict=add_feed_dict,\n            add_fetch_lst=add_fetch_lst\n        )\n        losses = other_rlts[-1]\n\n        return preds, losses\n\n    def loss(self, audios, gtruths):\n\n        if self.use_default_feed_fetch:\n            return self.loss_with_add_feed_fetch(\n                audios, gtruths,\n                add_feed_dict=self.default_add_feed_dict,\n                add_fetch_lst=self.default_add_fetch_lst\n            )\n\n        return self.loss_with_add_feed_fetch(audios, gtruths)\n\n    def loss_with_add_feed_fetch(self, audios, gtruths=None, add_feed_dict=None, add_fetch_lst=None, beam_decode=True):\n        \"\"\"\n        transcribe audios\n        call_back: set True to call a callback with will normally set additional feed_dict or fetch list.\n        \"\"\"\n        # this enables others to change additional feed_dict or fetch list if necessary\n        if gtruths is not None:\n            fetch_lst = [\n                self.model_output.logit_probs,\n                self.model_output.loss,\n                self.model_output.features_len\n            ]\n            feed_dict = {\n                self.model_inputs.audio_input: audios,\n                self.model_inputs.gtruth: gtruths\n            }\n        else:\n            # if gtruth is none, we do not fetch ctc_loss\n            fetch_lst = [\n                self.model_output.logit_probs,\n                self.model_output.features_len\n            ]\n            feed_dict = {\n                self.model_inputs.audio_input: audios,\n            }\n\n        # add extra information\n        if add_fetch_lst is not None:\n            fetch_lst.extend(add_fetch_lst)\n\n        if add_feed_dict is not None:\n            for key, val in add_feed_dict.items():\n                feed_dict[key] = val\n\n        run_rlts = self.session.run(\n            fetches=fetch_lst,\n            feed_dict=feed_dict\n        )\n\n        loss = None\n        if gtruths is not None:\n            logits_probs, loss, features_len = run_rlts[0], run_rlts[1], run_rlts[2]\n            other_rlts = run_rlts[3:]\n        else:\n            logits_probs, features_len = run_rlts[0], run_rlts[1]\n            other_rlts = run_rlts[2:]\n\n        if beam_decode is False:\n            return None, loss, other_rlts\n\n        num_processes = cpu_count()\n        beam_width = 100    # same as Carlini et al. 2018\n        decoded = ctc_beam_search_decoder_batch(logits_probs, features_len, Config.alphabet, beam_size=beam_width,\n                                                num_processes=num_processes, scorer=self.scorer,\n                                                cutoff_prob=FLAGS.cutoff_prob, cutoff_top_n=FLAGS.cutoff_top_n)\n        predictions = [d[0][1] for d in decoded]\n\n        return predictions, loss, other_rlts\n\n    def grads_wrt_input(self, audios, gtruths):\n        \"\"\"\n        return predictions, loss value, grads w.r.t audio waves, spectrogram and grads w.r.t spectrogram\n        \"\"\"\n        if self.grads_input_audio_opt is None:\n            assert self.grads_log_mel_opt is None\n            # create the opt once to calculate grads\n            self.grads_input_audio_opt = tf.gradients(self.model_output.loss, self.model_inputs.audio_input)\n            self.grads_log_mel_opt = tf.gradients(self.model_output.loss, self.log_mel_features)\n\n        predictions, loss, other_rlts = self.loss_with_add_feed_fetch(\n                audios, gtruths,\n                add_feed_dict=self.default_add_feed_dict,\n                add_fetch_lst=[self.grads_input_audio_opt, self.log_mel_features, self.grads_log_mel_opt]\n            )\n\n        audio_grads = other_rlts[0]\n        audio_grads = audio_grads[0]\n\n        log_mel = other_rlts[1]\n        log_mel = np.transpose(log_mel, (0, 2, 1))\n\n        log_mel_grads = other_rlts[2]\n        log_mel_grads = log_mel_grads[0]\n        log_mel_grads = np.transpose(log_mel_grads, (0, 2, 1))\n\n        return predictions, loss, audio_grads, log_mel, log_mel_grads\n'\n' returned non-zero exit status 1.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-771045ff0e03>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shell'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'eval \"$(conda shell.bash hook)\"\\nconda activate myenv\\n\\n# Install required dependencies, including matching DeepSpeech and CTC decoder versions\\npip install absl-py==0.9.0 attrdict==2.0.1 deepspeech numpy==1.16.0 progressbar2==3.47.0 python-utils==2.3.0 six==1.13.0 pandas==0.25.3 absl-py argparse semver pyxdg resampy pyogg\\npip uninstall ds_ctcdecoder -y\\npip3 install ds-ctcdecoder==0.10.0-alpha.3\\n\\n# Run your Python script\\npython -c \\'\\n\\n# import sys\\n# sys.path.append(\"/content/DeepSpeech/training\")\\nimport tensorflow as tf\\nimport tensorflow.compat.v1 as tfv1\\nimport numpy as np\\n\\nfrom DeepSpeech.training.deepspeech_training.train import create_model as ds_create_model\\nfrom DeepSpeech.training.deepspeech_training.util.config import Config\\nfrom DeepSpeech.training.deepspeech_training.util.flags import FLAGS\\n\\nfrom multiprocessing import cpu_count\\nfrom ds_ctcdecoder import ctc_beam_search_decoder_batch, Scorer\\n\\nfrom asr_model_base import ASRModelBase\\n\\n\\nclass MozillaDSModel(ASRModelBase):\\n    \"\"\"\\n    Mozilla DeepSpeech model\\n    wrap the implementation of of https://github.com/mozilla/DeepSpeech\\n    Release 0.8.2\\n    \"\"\"\\n\\n    class Inputs:\\n        def __init__(self):\\n            # model input consists of \"audio_input\", \"gtruth\"\\n            self.audio_input = None\\n            ...\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m       \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2471\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2473\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2474\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_shell_cell_magic\u001b[0;34m(args, cmd)\u001b[0m\n\u001b[1;32m    110\u001b[0m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparsed_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_errors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_returncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36mcheck_returncode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcheck_returncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m       raise subprocess.CalledProcessError(\n\u001b[0m\u001b[1;32m    138\u001b[0m           \u001b[0mreturncode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m       )\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command 'eval \"$(conda shell.bash hook)\"\nconda activate myenv\n\n# Install required dependencies, including matching DeepSpeech and CTC decoder versions\npip install absl-py==0.9.0 attrdict==2.0.1 deepspeech numpy==1.16.0 progressbar2==3.47.0 python-utils==2.3.0 six==1.13.0 pandas==0.25.3 absl-py argparse semver pyxdg resampy pyogg\npip uninstall ds_ctcdecoder -y\npip3 install ds-ctcdecoder==0.10.0-alpha.3\n\n# Run your Python script\npython -c '\n\n# import sys\n# sys.path.append(\"/content/DeepSpeech/training\")\nimport tensorflow as tf\nimport tensorflow.compat.v1 as tfv1\nimport numpy as np\n\nfrom DeepSpeech.training.deepspeech_training.train import create_model as ds_create_model\nfrom DeepSpeech.training.deepspeech_training.util.config import Config\nfrom DeepSpeech.training.deepspeech_training.util.flags import FLAGS\n\nfrom multiprocessing import cpu_count\nfrom ds_ctcdecoder import ctc_beam_search_decoder_batch, Scorer\n\nfrom asr_model_base import ASRModelBase\n\n\nclass MozillaDSModel(ASRModelBase):\n    \"\"\"\n    Mozilla DeepSpeech model\n    wrap the implementation of of https://github.com/mozilla/DeepSpeech\n    Release 0.8.2\n    \"\"\"\n\n    class Inputs:\n        def __init__(self):\n            # model input consists of \"audio_input\", \"gtruth\"\n            self.audio_input = None\n            self.gtruth = None\n\n    class Outputs:\n        def __init__(self):\n            #  model output\n            self.features_len = None\n            self.logits = None        # batch\n            major\n            self.logit_probs = None\n            self.batch_losses = None  # batch_losses is not returned by default, you should manually fetch it\n            self.loss = None\n\n    def __init__(self, scorer_path=None):\n        super().__init__()\n\n        self.scorer = None\n        if scorer_path is not None:\n            # read the scorer\n            print(f\"reading scorer from {scorer_path}...\")\n            self.scorer = Scorer(FLAGS.lm_alpha, FLAGS.lm_beta, scorer_path, Config.alphabet)\n\n        self.model_inputs = MozillaDSModel.Inputs()\n        self.model_output = MozillaDSModel.Outputs()\n        self.mfcc_features = None\n        self.log_mel_features = None\n\n        self.session = None\n        self.chkpnt_skip_prefix = None\n        self.global_init_opt = None  # the opt to initialize global variables\n\n        self.signal_start_callbk = None  # callback when model is signaled start\n        self.signal_end_callbk = None  # callback when model is signaled start\n\n        self.use_default_feed_fetch = True  # whether to use\n        self.default_add_fetch_lst = None  # default additional fetch list\n        self.default_add_feed_dict = None  # default additional feed dict\n\n        # used to get grads w.r.t input\n        self.grads_input_audio_opt = None\n        self.grads_log_mel_opt = None\n\n\n    def get_win_stride(self):\n        return Config.audio_step_samples / self.get_sr()\n\n    def get_win_size(self):\n        return Config.audio_window_samples / self.get_sr()\n\n    def get_sr(self):\n        return FLAGS.audio_sample_rate\n\n    def get_labels(self):\n        raise NotImplementedError\n\n    def get_spec_type(self):\n        return \"mfccs\"\n\n    def get_session_config(self):\n        \"\"\"\n        example: with tfv1.Session(config=Config.session_config) as session:\n        \"\"\"\n        return Config.session_config\n\n    @staticmethod\n    def audio_to_features(audio_input):\n        stfts = tf.signal.stft(audio_input,\n                               frame_length=int(Config.audio_window_samples),\n                               frame_step=int(Config.audio_step_samples),\n                               window_fn=tf.signal.hann_window)\n        spectrograms = tf.abs(stfts)\n\n        # Warp the linear scale spectrograms into the mel-scale.\n        num_spectrogram_bins = stfts.shape[-1].value\n        lower_edge_hertz, upper_edge_hertz, num_mel_bins = 0, FLAGS.audio_sample_rate / 2, 80\n        linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(\n            num_mel_bins, num_spectrogram_bins, FLAGS.audio_sample_rate, lower_edge_hertz,\n            upper_edge_hertz)\n        mel_spectrograms = tf.tensordot(\n            spectrograms, linear_to_mel_weight_matrix, 1)\n        mel_spectrograms.set_shape(spectrograms.shape[:-1].concatenate(\n            linear_to_mel_weight_matrix.shape[-1:]))\n\n        # Compute a stabilized log to get log-magnitude mel-scale spectrograms.\n        log_mel_spectrograms = tf.math.log(mel_spectrograms + 1e-6)\n\n        # Compute MFCCs from log_mel_spectrograms and take the first Config.n_input.\n        mfccs = tf.signal.mfccs_from_log_mel_spectrograms(\n            log_mel_spectrograms)[..., :Config.n_input]\n\n        return log_mel_spectrograms, mfccs\n\n    def create_model(self, audio_input, log_mel_features=None, mfcc_features=None):\n        \"\"\"\n        from audio raw data to transcriptions\n        audio: place_holder (None, None, 1)\n        the mfcc generated : tf.Tensor(tf.float32, shape=[None, None, Config.n_input])\n        true_trans example: tf.sparse_placeholder(tf.int32)\n\n        model_input: the input for feed_dic. If not set, this model input will be audio_input\n        \"\"\"\n        if (log_mel_features is not None) and (mfcc_features is not None):\n            self.log_mel_features, self.mfcc_features = log_mel_features, mfcc_features\n        else:\n            self.log_mel_features, self.mfcc_features = MozillaDSModel.audio_to_features(audio_input)\n\n        batch_size = tf.shape(self.mfcc_features)[0]\n        sample_len = tf.shape(self.mfcc_features)[1]\n        features_len = tf.repeat(sample_len, batch_size)    # assume all samples have the same length\n\n        # One rate per layer\n        no_dropout = [None] * 6\n        logits, _ = ds_create_model(\n            batch_x=self.mfcc_features,\n            seq_length=features_len,\n            dropout=no_dropout\n        )\n\n        # Transpose to batch major and apply softmax for decoder\n        batch_logits = tf.transpose(a=logits, perm=[1, 0, 2])\n        logit_probs = tf.nn.softmax(batch_logits)\n\n        gtruth = tf.sparse_placeholder(tf.int32)\n        batch_losses = tfv1.nn.ctc_loss(labels=gtruth,\n                                  inputs=logits,\n                                  sequence_length=features_len)\n\n        loss = tf.math.reduce_sum(batch_losses) / tf.cast(batch_size, tf.float32)\n\n        tfv1.train.get_or_create_global_step()\n\n        # record inputs and outputs\n        self.model_inputs.audio_input = audio_input\n        self.model_inputs.gtruth = gtruth\n\n        self.model_output.features_len = features_len\n        self.model_output.logits = batch_logits\n        self.model_output.logit_probs = logit_probs\n        self.model_output.batch_losses = batch_losses\n        self.model_output.loss = loss\n\n    def _load_checkpoint(self, session, checkpoint_path):\n        # Load the checkpoint and put all variables into loading list\n        # we will exclude variables we do not wish to load and then\n        # we will initialize them instead\n        ckpt = tfv1.train.load_checkpoint(checkpoint_path)\n        vars_in_ckpt = frozenset(ckpt.get_variable_to_shape_map().keys())\n        load_vars = set(tfv1.global_variables())\n        init_vars = set()\n\n        # We explicitly allow the learning rate variable to be missing for backwards\n        # compatibility with older checkpoints.\n        lr_var = set(v for v in load_vars if v.op.name == \"learning_rate\")\n        if lr_var and (\"learning_rate\" not in vars_in_ckpt or FLAGS.force_initialize_learning_rate):\n            assert len(lr_var) <= 1\n            load_vars -= lr_var\n            init_vars |= lr_var\n\n        for v in sorted(load_vars, key=lambda v: v.op.name):\n            if self.chkpnt_skip_prefix is not None and v.op.name.find(self.chkpnt_skip_prefix) == 0:\n                print(\"skipping varible: %s\" % v.op.name)\n                continue\n\n            print(\"Loading variable from checkpoint: %s\" % (v.op.name))\n            v.load(ckpt.get_tensor(v.op.name), session=session)\n\n        for v in sorted(init_vars, key=lambda v: v.op.name):\n            print(\"Initializing variable: %s\" % (v.op.name))\n            session.run(v.initializer)\n\n    def load_ckpnt(self, session):\n        \"\"\"\n        load a check point\n        \"\"\"\n        checkpoint = tfv1.train.get_checkpoint_state(FLAGS.load_checkpoint_dir, \"best_dev_checkpoint\")\n        if not checkpoint:\n            assert False, \"Cannot find the check point file.\"\n        ckpt_path = checkpoint.model_checkpoint_path\n        self._load_checkpoint(session, ckpt_path)\n\n    def is_model_created(self):\n        return self.model_output.loss is not None\n\n    def signal_start(self):\n        \"\"\"\n        create a session for running\n        also, we load the check point here\n        \"\"\"\n        self.session = tfv1.Session(config=Config.session_config)\n\n        if self.global_init_opt is None:\n            self.global_init_opt = tf.initializers.global_variables()  # only create this opt once\n        self.session.run(self.global_init_opt)\n\n        if self.signal_start_callbk is not None:\n            self.signal_start_callbk()\n\n        self.load_ckpnt(self.session)   # each time we reload the check point when a new session starts\n\n        # reset global step\n        g_step = tfv1.train.get_global_step()\n        if g_step is not None:\n            print(\"found global step val: {}\".format(g_step.eval(self.session)))\n            self.session.run(g_step.initializer)\n            print(\"reset global step val: {}\".format(g_step.eval(self.session)))\n\n\n    def signal_end(self):\n        \"\"\"\n        close a session\n        \"\"\"\n        if self.signal_end_callbk is not None:\n            self.signal_end_callbk()\n\n        self.session.close()\n        self.session = None\n\n    def eval(self, need_grads):\n        \"\"\"\n        set model in evaluation mode\n        \"\"\"\n        pass  # do nothing here as we do not set dropout during creation\n\n\n\n    def repeat_gtruth(self, org_gtruth, repeats):\n        \"\"\"\n        repeat gtruth\n        \"\"\"\n        indices, sequence, shape = org_gtruth\n        assert shape[0] == 1, \"Now, only support repeating sparse with one row\"\n\n        cols = shape[1]\n\n        batch_shape = shape.copy()\n        batch_shape[0] = repeats  # repeats*dim matrix\n\n        batch_sequence = []\n        batch_indices = np.zeros(shape=(repeats*cols, 2), dtype=indices.dtype)\n        for i in range(repeats):\n            batch_sequence.extend(sequence)\n            for cur_col in range(cols):\n                batch_indices[i*cols+cur_col, 0] = i\n                batch_indices[i*cols+cur_col, 1] = indices[cur_col, 1]\n\n        return batch_indices, batch_sequence, batch_shape\n\n    def transcribe(self, audios):\n        trans, _, _ = self.loss_with_add_feed_fetch(audios)\n        return trans\n\n    def transcribe_same_len(self, audios, gtruths):\n        \"\"\"\n        transcribe a batch of audios with same length\n        \"\"\"\n        add_feed_dict = None\n        add_fetch_lst = None\n        if self.use_default_feed_fetch:\n            add_feed_dict = self.default_add_feed_dict.copy() if self.default_add_feed_dict is not None else None\n            add_fetch_lst = self.default_add_fetch_lst.copy() if self.default_add_fetch_lst is not None else []\n\n        # we want to get losses of each audio\n        add_fetch_lst.append(self.model_output.batch_losses)\n\n        preds, loss, other_rlts = self.loss_with_add_feed_fetch(\n            audios, gtruths,\n            add_feed_dict=add_feed_dict,\n            add_fetch_lst=add_fetch_lst\n        )\n        losses = other_rlts[-1]\n\n        return preds, losses\n\n    def loss(self, audios, gtruths):\n\n        if self.use_default_feed_fetch:\n            return self.loss_with_add_feed_fetch(\n                audios, gtruths,\n                add_feed_dict=self.default_add_feed_dict,\n                add_fetch_lst=self.default_add_fetch_lst\n            )\n\n        return self.loss_with_add_feed_fetch(audios, gtruths)\n\n    def loss_with_add_feed_fetch(self, audios, gtruths=None, add_feed_dict=None, add_fetch_lst=None, beam_decode=True):\n        \"\"\"\n        transcribe audios\n        call_back: set True to call a callback with will normally set additional feed_dict or fetch list.\n        \"\"\"\n        # this enables others to change additional feed_dict or fetch list if necessary\n        if gtruths is not None:\n            fetch_lst = [\n                self.model_output.logit_probs,\n                self.model_output.loss,\n                self.model_output.features_len\n            ]\n            feed_dict = {\n                self.model_inputs.audio_input: audios,\n                self.model_inputs.gtruth: gtruths\n            }\n        else:\n            # if gtruth is none, we do not fetch ctc_loss\n            fetch_lst = [\n                self.model_output.logit_probs,\n                self.model_output.features_len\n            ]\n            feed_dict = {\n                self.model_inputs.audio_input: audios,\n            }\n\n        # add extra information\n        if add_fetch_lst is not None:\n            fetch_lst.extend(add_fetch_lst)\n\n        if add_feed_dict is not None:\n            for key, val in add_feed_dict.items():\n                feed_dict[key] = val\n\n        run_rlts = self.session.run(\n            fetches=fetch_lst,\n            feed_dict=feed_dict\n        )\n\n        loss = None\n        if gtruths is not None:\n            logits_probs, loss, features_len = run_rlts[0], run_rlts[1], run_rlts[2]\n            other_rlts = run_rlts[3:]\n        else:\n            logits_probs, features_len = run_rlts[0], run_rlts[1]\n            other_rlts = run_rlts[2:]\n\n        if beam_decode is False:\n            return None, loss, other_rlts\n\n        num_processes = cpu_count()\n        beam_width = 100    # same as Carlini et al. 2018\n        decoded = ctc_beam_search_decoder_batch(logits_probs, features_len, Config.alphabet, beam_size=beam_width,\n                                                num_processes=num_processes, scorer=self.scorer,\n                                                cutoff_prob=FLAGS.cutoff_prob, cutoff_top_n=FLAGS.cutoff_top_n)\n        predictions = [d[0][1] for d in decoded]\n\n        return predictions, loss, other_rlts\n\n    def grads_wrt_input(self, audios, gtruths):\n        \"\"\"\n        return predictions, loss value, grads w.r.t audio waves, spectrogram and grads w.r.t spectrogram\n        \"\"\"\n        if self.grads_input_audio_opt is None:\n            assert self.grads_log_mel_opt is None\n            # create the opt once to calculate grads\n            self.grads_input_audio_opt = tf.gradients(self.model_output.loss, self.model_inputs.audio_input)\n            self.grads_log_mel_opt = tf.gradients(self.model_output.loss, self.log_mel_features)\n\n        predictions, loss, other_rlts = self.loss_with_add_feed_fetch(\n                audios, gtruths,\n                add_feed_dict=self.default_add_feed_dict,\n                add_fetch_lst=[self.grads_input_audio_opt, self.log_mel_features, self.grads_log_mel_opt]\n            )\n\n        audio_grads = other_rlts[0]\n        audio_grads = audio_grads[0]\n\n        log_mel = other_rlts[1]\n        log_mel = np.transpose(log_mel, (0, 2, 1))\n\n        log_mel_grads = other_rlts[2]\n        log_mel_grads = log_mel_grads[0]\n        log_mel_grads = np.transpose(log_mel_grads, (0, 2, 1))\n\n        return predictions, loss, audio_grads, log_mel, log_mel_grads\n'\n' returned non-zero exit status 1."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **UPLOAD TESTTING AUDIO**"
      ],
      "metadata": {
        "id": "sIDznAMBicZ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary packages\n",
        "!pip install IPython\n",
        "!pip install scipy\n",
        "\n",
        "from IPython.display import Audio\n",
        "from scipy.io import wavfile\n",
        "\n",
        "# Set to True if we are in Google Colaboratory, otherwise False\n",
        "colaboratory = True\n",
        "\n",
        "if colaboratory:\n",
        "    # Load sound file from GitHub using the raw link\n",
        "    !wget -O garage_door.wav https://raw.githubusercontent.com/nganguyen1234/uow-research2024/main/260-123440-0017_open%20the%20garage%20door_1e-4.wav\n",
        "\n",
        "    # Clear output after import\n",
        "    from IPython.display import clear_output\n",
        "    clear_output()\n",
        "\n",
        "    print(\"Garage door sound loaded\")\n",
        "else:\n",
        "    print(\"We are not in Google Colaboratory\")\n",
        "    print(\"The file should already be on the computer\")\n",
        "\n",
        "# Load the audio file\n",
        "data = wavfile.read('garage_door.wav')\n",
        "\n",
        "# Separate the object elements\n",
        "framerate = data[0]\n",
        "sounddata = data[1]\n",
        "\n",
        "# Generate a player for the audio\n",
        "Audio(sounddata, rate=framerate)\n"
      ],
      "metadata": {
        "id": "znJXVdmmijeH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}